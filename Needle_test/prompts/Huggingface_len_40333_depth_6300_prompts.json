[{"role": "system", "content": "You are a helpful AI bot that answers questions for a user. Keep your response short and direct"}, {"role": "user", "content": "\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\nJuly 2010What hard liquor, cigarettes, heroin, and crack have in common is\nthat they're all more concentrated forms of less addictive predecessors.\nMost if not all the things we describe as addictive are.  And the\nscary thing is, the process that created them is accelerating.We wouldn't want to stop it.  It's the same process that cures\ndiseases: technological progress.  Technological progress means\nmaking things do more of what we want.  When the thing we want is\nsomething we want to want, we consider technological progress good.\nIf some new technique makes solar cells x% more efficient, that\nseems strictly better.  When progress concentrates something we\ndon't want to want\u2014when it transforms opium into heroin\u2014it seems\nbad.  But it's the same process at work.\n[1]No one doubts this process is accelerating, which means increasing\nnumbers of things we like will be transformed into things we like\ntoo much.\n[2]As far as I know there's no word for something we like too much.\nThe closest is the colloquial sense of \"addictive.\" That usage has\nbecome increasingly common during my lifetime.  And it's clear why:\nthere are an increasing number of things we need it for.  At the\nextreme end of the spectrum are crack and meth.  Food has been\ntransformed by a combination of factory farming and innovations in\nfood processing into something with way more immediate bang for the\nbuck, and you can see the results in any town in America.  Checkers\nand solitaire have been replaced by World of Warcraft and FarmVille.\nTV has become much more engaging, and even so it can't compete with Facebook.The world is more addictive than it was 40 years ago.   And unless\nthe forms of technological progress that produced these things are\nsubject to different laws than technological progress in general,\nthe world will get more addictive in the next 40 years than it did\nin the last 40.The next 40 years will bring us some wonderful things.  I don't\nmean to imply they're all to be avoided.  Alcohol is a dangerous\ndrug, but I'd rather live in a world with wine than one without.\nMost people can coexist with alcohol; but you have to be careful.\nMore things we like will mean more things we have to be careful\nabout.Most people won't, unfortunately.  Which means that as the world\nbecomes more addictive, the two senses in which one can live a\nnormal life will be driven ever further apart.  One sense of \"normal\"\nis statistically normal: what everyone else does.  The other is the\nsense we mean when we talk about the normal operating range of a\npiece of machinery: what works best.These two senses are already quite far apart.  Already someone\ntrying to live well would seem eccentrically abstemious in most of\nthe US.  That phenomenon is only going to become more pronounced.\nYou can probably take it as a rule of thumb from now on that if\npeople don't think you're weird, you're living badly.Societies eventually develop antibodies to addictive new things.\nI've seen that happen with cigarettes.  When cigarettes first\nappeared, they spread the way an infectious disease spreads through\na previously isolated population.  Smoking rapidly became a\n(statistically) normal thing.  There were ashtrays everywhere.  We\nhad ashtrays in our house when I was a kid, even though neither of\nmy parents smoked.  You had to for guests.As knowledge spread about the dangers of smoking, customs changed.\nIn the last 20 years, smoking has been transformed from something\nthat seemed totally normal into a rather seedy habit: from something\nmovie stars did in publicity shots to something small huddles of\naddicts do outside the doors of office buildings.  A lot of the\nchange was due to legislation, of course, but the legislation\ncouldn't have happened if customs hadn't already changed.It took a while though\u2014on the order of 100 years.  And unless the\nrate at which social antibodies evolve can increase to match the\naccelerating rate at which technological progress throws off new\naddictions, we'll be increasingly unable to rely on customs to\nprotect us.\n[3]\nUnless we want to be canaries in the coal mine\nof each new addiction\u2014the people whose sad example becomes a\nlesson to future generations\u2014we'll have to figure out for ourselves\nwhat to avoid and how.  It will actually become a reasonable strategy\n(or a more reasonable strategy) to suspect \neverything new.In fact, even that won't be enough.  We'll have to worry not just\nabout new things, but also about existing things becoming more\naddictive.  That's what bit me.  I've avoided most addictions, but\nthe Internet got me because it became addictive while I was using\nit.\n[4]Most people I know have problems with Internet addiction.  We're\nall trying to figure out our own customs for getting free of it.\nThat's why I don't have an iPhone, for example; the last thing I\nwant is for the Internet to follow me out into the world.\n[5]\nMy latest trick is taking long hikes.  I used to think running was a\nbetter form of exercise than hiking because it took less time.  Now\nthe slowness of hiking seems an advantage, because the longer I\nspend on the trail, the longer I have to think without interruption.Sounds pretty eccentric, doesn't it?  It always will when you're\ntrying to solve problems where there are no customs yet to guide\nyou.  Maybe I can't plead Occam's razor; maybe I'm simply eccentric.\nBut if I'm right about the acceleration of addictiveness, then this\nkind of lonely squirming to avoid it will increasingly be the fate\nof anyone who wants to get things done.  We'll increasingly be\ndefined by what we say no to.\nNotes[1]\nCould you restrict technological progress to areas where you\nwanted it?  Only in a limited way, without becoming a police state.\nAnd even then your restrictions would have undesirable side effects.\n\"Good\" and \"bad\" technological progress aren't sharply differentiated,\nso you'd find you couldn't slow the latter without also slowing the\nformer.  And in any case, as Prohibition and the \"war on drugs\"\nshow, bans often do more harm than good.[2]\nTechnology has always been accelerating.  By Paleolithic\nstandards, technology evolved at a blistering pace in the Neolithic\nperiod.[3]\nUnless we mass produce social customs.  I suspect the recent\nresurgence of evangelical Christianity in the US is partly a reaction\nto drugs.  In desperation people reach for the sledgehammer; if\ntheir kids won't listen to them, maybe they'll listen to God.  But\nthat solution has broader consequences than just getting kids to\nsay no to drugs.  You end up saying no to \nscience as well.\nI worry we may be heading for a future in which only a few people\nplot their own itinerary through no-land, while everyone else books\na package tour.  Or worse still, has one booked for them by the\ngovernment.[4]\nPeople commonly use the word \"procrastination\" to describe\nwhat they do on the Internet.  It seems to me too mild to describe\nwhat's happening as merely not-doing-work.  We don't call it\nprocrastination when someone gets drunk instead of working.[5]\nSeveral people have told me they like the iPad because it\nlets them bring the Internet into situations where a laptop would\nbe too conspicuous.  In other words, it's a hip flask.  (This is\ntrue of the iPhone too, of course, but this advantage isn't as\nobvious because it reads as a phone, and everyone's used to those.)Thanks to Sam Altman, Patrick Collison, Jessica Livingston, and\nRobert Morris for reading drafts of this.October 2015When I talk to a startup that's been operating for more than 8 or\n9 months, the first thing I want to know is almost always the same.\nAssuming their expenses remain constant and their revenue growth\nis what it has been over the last several months, do they make it to\nprofitability on the money they have left?  Or to put it more\ndramatically, by default do they live or die?The startling thing is how often the founders themselves don't know.\nHalf the founders I talk to don't know whether they're default alive\nor default dead.If you're among that number, Trevor Blackwell has made a handy\ncalculator you can use to find out.The reason I want to know first whether a startup is default alive\nor default dead is that the rest of the conversation depends on the\nanswer.  If the company is default alive, we can talk about ambitious\nnew things they could do.  If it's default dead, we probably need\nto talk about how to save it.  We know the current trajectory ends\nbadly.  How can they get off that trajectory?Why do so few founders know whether they're default alive or default\ndead?  Mainly, I think, because they're not used to asking that.\nIt's not a question that makes sense to ask early on, any more than\nit makes sense to ask a 3 year old how he plans to support\nhimself.  But as the company grows older, the question switches from\nmeaningless to critical.  That kind of switch often takes people\nby surprise.I propose the following solution: instead of starting to ask too\nlate whether you're default alive or default dead, start asking too\nearly.  It's hard to say precisely when the question switches\npolarity.  But it's probably not that dangerous to start worrying\ntoo early that you're default dead, whereas it's very dangerous to\nstart worrying too late.The reason is a phenomenon I wrote about earlier: the\nfatal pinch.\nThe fatal pinch is default dead + slow growth + not enough\ntime to fix it.  And the way founders end up in it is by not realizing\nthat's where they're headed.There is another reason founders don't ask themselves whether they're\ndefault alive or default dead: they assume it will be easy to raise\nmore money.  But that assumption is often false, and worse still, the\nmore you depend on it, the falser it becomes.Maybe it will help to separate facts from hopes. Instead of thinking\nof the future with vague optimism, explicitly separate the components.\nSay \"We're default dead, but we're counting on investors to save\nus.\" Maybe as you say that, it will set off the same alarms in your\nhead that it does in mine.  And if you set off the alarms sufficiently\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\nsaving you.  As a rule their interest is a function of\ngrowth.  If you have steep revenue growth, say over 5x a year, you\ncan start to count on investors being interested even if you're not\nprofitable.\n[1]\nBut investors are so fickle that you can never\ndo more than start to count on them.  Sometimes something about your\nbusiness will spook investors even if your growth is great.  So no\nmatter how good your growth is, you can never safely treat fundraising\nas more than a plan A. You should always have a plan B as well: you\nshould know (as in write down) precisely what you'll need to do to\nsurvive if you can't raise more money, and precisely when you'll \nhave to switch to plan B if plan A isn't working.In any case, growing fast versus operating cheaply is far from the\nsharp dichotomy many founders assume it to be.  In practice there\nis surprisingly little connection between how much a startup spends\nand how fast it grows.  When a startup grows fast, it's usually\nbecause the product hits a nerve, in the sense of hitting some big\nneed straight on.  When a startup spends a lot, it's usually because\nthe product is expensive to develop or sell, or simply because\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\nhow to avoid the fatal pinch, but how to avoid being default dead.\nThat one is easy: don't hire too fast.  Hiring too fast is by far\nthe biggest killer of startups that raise money.\n[2]Founders tell themselves they need to hire in order to grow.  But\nmost err on the side of overestimating this need rather than\nunderestimating it.  Why?  Partly because there's so much work to\ndo.  Naive founders think that if they can just hire enough\npeople, it will all get done.  Partly because successful startups have\nlots of employees, so it seems like that's what one does in order\nto be successful.  In fact the large staffs of successful startups\nare probably more the effect of growth than the cause.  And\npartly because when founders have slow growth they don't want to\nface what is usually the real reason: the product is not appealing\nenough.Plus founders who've just raised money are often encouraged to\noverhire by the VCs who funded them.  Kill-or-cure strategies are\noptimal for VCs because they're protected by the portfolio effect.\nVCs want to blow you up, in one sense of the phrase or the other.\nBut as a founder your incentives are different.  You want above all\nto survive.\n[3]Here's a common way startups die.  They make something moderately\nappealing and have decent initial growth. They raise their first\nround fairly easily, because the founders seem smart and the idea\nsounds plausible. But because the product is only moderately\nappealing, growth is ok but not great.  The founders convince\nthemselves that hiring a bunch of people is the way to boost growth.\nTheir investors agree.  But (because the product is only moderately\nappealing) the growth never comes.  Now they're rapidly running out\nof runway.  They hope further investment will save them. But because\nthey have high expenses and slow growth, they're now unappealing\nto investors. They're unable to raise more, and the company dies.What the company should have done is address the fundamental problem:\nthat the product is only moderately appealing.  Hiring people is\nrarely the way to fix that.  More often than not it makes it harder.\nAt this early stage, the product needs to evolve more than to be\n\"built out,\" and that's usually easier with fewer people.\n[4]Asking whether you're default alive or default dead may save you\nfrom this.  Maybe the alarm bells it sets off will counteract the\nforces that push you to overhire.  Instead you'll be compelled to\nseek growth in other ways. For example, by doing\nthings that don't scale, or by redesigning the product in the\nway only founders can.\nAnd for many if not most startups, these paths to growth will be\nthe ones that actually work.Airbnb waited 4 months after raising money at the end of Y\u00a0Combinator\nbefore they hired their first employee.  In the meantime the founders\nwere terribly overworked.  But they were overworked evolving Airbnb\ninto the astonishingly successful organism it is now.Notes[1]\nSteep usage growth will also interest investors.  Revenue\nwill ultimately be a constant multiple of usage, so x% usage growth\npredicts x% revenue growth.  But in practice investors discount\nmerely predicted revenue, so if you're measuring usage you need a\nhigher growth rate to impress investors.[2]\nStartups that don't raise money are saved from hiring too\nfast because they can't afford to. But that doesn't mean you should\navoid raising money in order to avoid this problem, any more than\nthat total abstinence is the only way to avoid becoming an alcoholic.[3]\nI would not be surprised if VCs' tendency to push founders\nto overhire is not even in their own interest.  They don't know how\nmany of the companies that get killed by overspending might have\ndone well if they'd survived.  My guess is a significant number.[4]\nAfter reading a draft, Sam Altman wrote:\"I think you should make the hiring point more strongly.  I think\nit's roughly correct to say that YC's most successful companies\nhave never been the fastest to hire, and one of the marks of a great\nfounder is being able to resist this urge.\"Paul Buchheit adds:\"A related problem that I see a lot is premature scaling\u2014founders\ntake a small business that isn't really working (bad unit economics,\ntypically) and then scale it up because they want impressive growth\nnumbers. This is similar to over-hiring in that it makes the business\nmuch harder to fix once it's big, plus they are bleeding cash really\nfast.\"\nThanks to Sam Altman, Paul Buchheit, Joe Gebbia, Jessica Livingston,\nand Geoff Ralston for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nNovember 2009I don't think Apple realizes how badly the App Store approval process\nis broken.  Or rather, I don't think they realize how much it matters\nthat it's broken.The way Apple runs the App Store has harmed their reputation with\nprogrammers more than anything else they've ever done. \nTheir reputation with programmers used to be great.\nIt used to be the most common complaint you heard\nabout Apple was that their fans admired them too uncritically.\nThe App Store has changed that.  Now a lot of programmers\nhave started to see Apple as evil.How much of the goodwill Apple once had with programmers have they\nlost over the App Store?  A third?  Half?  And that's just so far.\nThe App Store is an ongoing karma leak.* * *How did Apple get into this mess?  Their fundamental problem is\nthat they don't understand software.They treat iPhone apps the way they treat the music they sell through\niTunes.  Apple is the channel; they own the user; if you want to\nreach users, you do it on their terms. The record labels agreed,\nreluctantly.  But this model doesn't work for software.  It doesn't\nwork for an intermediary to own the user.  The software business\nlearned that in the early 1980s, when companies like VisiCorp showed\nthat although the words \"software\" and \"publisher\" fit together,\nthe underlying concepts don't.  Software isn't like music or books.\nIt's too complicated for a third party to act as an intermediary\nbetween developer and user.   And yet that's what Apple is trying\nto be with the App Store: a software publisher.  And a particularly\noverreaching one at that, with fussy tastes and a rigidly enforced\nhouse style.If software publishing didn't work in 1980, it works even less now\nthat software development has evolved from a small number of big\nreleases to a constant stream of small ones.  But Apple doesn't\nunderstand that either.  Their model of product development derives\nfrom hardware.  They work on something till they think it's finished,\nthen they release it.  You have to do that with hardware, but because\nsoftware is so easy to change, its design can benefit from evolution.\nThe standard way to develop applications now is to launch fast and\niterate.  Which means it's a disaster to have long, random delays\neach time you release a new version.Apparently Apple's attitude is that developers should be more careful\nwhen they submit a new version to the App Store.  They would say\nthat.  But powerful as they are, they're not powerful enough to\nturn back the evolution of technology.  Programmers don't use\nlaunch-fast-and-iterate out of laziness.  They use it because it\nyields the best results.  By obstructing that process, Apple is\nmaking them do bad work, and programmers hate that as much as Apple\nwould.How would Apple like it if when they discovered a serious bug in\nOS\u00a0X, instead of releasing a software update immediately, they had\nto submit their code to an intermediary who sat on it for a month\nand then rejected it because it contained an icon they didn't like?By breaking software development, Apple gets the opposite of what\nthey intended: the version of an app currently available in the App\nStore tends to be an old and buggy one.  One developer told me:\n\n  As a result of their process, the App Store is full of half-baked\n  applications. I make a new version almost every day that I release\n  to beta users. The version on the App Store feels old and crappy.\n  I'm sure that a lot of developers feel this way: One emotion is\n  \"I'm not really proud about what's in the App Store\", and it's\n  combined with the emotion \"Really, it's Apple's fault.\"\n\nAnother wrote:\n\n  I believe that they think their approval process helps users by\n  ensuring quality.  In reality, bugs like ours get through all the\n  time and then it can take 4-8 weeks to get that bug fix approved,\n  leaving users to think that iPhone apps sometimes just don't work.\n  Worse for Apple, these apps work just fine on other platforms\n  that have immediate approval processes.\n\nActually I suppose Apple has a third misconception: that all the\ncomplaints about App Store approvals are not a serious problem.\nThey must hear developers complaining.  But partners and suppliers\nare always complaining.  It would be a bad sign if they weren't;\nit would mean you were being too easy on them.  Meanwhile the iPhone\nis selling better than ever.  So why do they need to fix anything?They get away with maltreating developers, in the short term, because\nthey make such great hardware.  I just bought a new 27\" iMac a\ncouple days ago.  It's fabulous.  The screen's too shiny, and the\ndisk is surprisingly loud, but it's so beautiful that you can't\nmake yourself care.So I bought it, but I bought it, for the first time, with misgivings.\nI felt the way I'd feel buying something made in a country with a\nbad human rights record.  That was new.  In the past when I bought\nthings from Apple it was an unalloyed pleasure.  Oh boy!  They make\nsuch great stuff.  This time it felt like a Faustian bargain.  They\nmake such great stuff, but they're such assholes.  Do I really want\nto support this company?* * *Should Apple care what people like me think?  What difference does\nit make if they alienate a small minority of their users?There are a couple reasons they should care.  One is that these\nusers are the people they want as employees.  If your company seems\nevil, the best programmers won't work for you.  That hurt Microsoft\na lot starting in the 90s.  Programmers started to feel sheepish\nabout working there.  It seemed like selling out.  When people from\nMicrosoft were talking to other programmers and they mentioned where\nthey worked, there were a lot of self-deprecating jokes about having\ngone over to the dark side.  But the real problem for Microsoft\nwasn't the embarrassment of the people they hired.  It was the\npeople they never got.  And you know who got them?  Google and\nApple.  If Microsoft was the Empire, they were the Rebel Alliance.\nAnd it's largely because they got more of the best people that\nGoogle and Apple are doing so much better than Microsoft today.Why are programmers so fussy about their employers' morals?  Partly\nbecause they can afford to be.  The best programmers can work\nwherever they want.  They don't have to work for a company they\nhave qualms about.But the other reason programmers are fussy, I think, is that evil\nbegets stupidity.  An organization that wins by exercising power\nstarts to lose the ability to win by doing better work.  And it's\nnot fun for a smart person to work in a place where the best ideas\naren't the ones that win.  I think the reason Google embraced \"Don't\nbe evil\" so eagerly was not so much to impress the outside world\nas to inoculate themselves against arrogance.\n[1]That has worked for Google so far.  They've become more\nbureaucratic, but otherwise they seem to have held true to their\noriginal principles. With Apple that seems less the case.  When you\nlook at the famous \n1984 ad \nnow, it's easier to imagine Apple as the\ndictator on the screen than the woman with the hammer.\n[2]\nIn fact, if you read the dictator's speech it sounds uncannily like a\nprophecy of the App Store.\n\n  We have triumphed over the unprincipled dissemination of facts.We have created, for the first time in all history, a garden of\n  pure ideology, where each worker may bloom secure from the pests\n  of contradictory and confusing truths.\n\nThe other reason Apple should care what programmers think of them\nis that when you sell a platform, developers make or break you.  If\nanyone should know this, Apple should.  VisiCalc made the Apple II.And programmers build applications for the platforms they use.  Most\napplications\u2014most startups, probably\u2014grow out of personal projects.\nApple itself did.  Apple made microcomputers because that's what\nSteve Wozniak wanted for himself.  He couldn't have afforded a\nminicomputer. \n[3]\n Microsoft likewise started out making interpreters\nfor little microcomputers because\nBill Gates and Paul Allen were interested in using them.  It's a\nrare startup that doesn't build something the founders use.The main reason there are so many iPhone apps is that so many programmers\nhave iPhones.  They may know, because they read it in an article,\nthat Blackberry has such and such market share.  But in practice\nit's as if RIM didn't exist. If they're going to build something,\nthey want to be able to use it themselves, and that means building\nan iPhone app.So programmers continue to develop iPhone apps, even though Apple\ncontinues to maltreat them.  They're like someone stuck in an abusive\nrelationship.  They're so attracted to the iPhone that they can't\nleave.  But they're looking for a way out.  One wrote:\n\n  While I did enjoy developing for the iPhone, the control they\n  place on the App Store does not give me the drive to develop\n  applications as I would like. In fact I don't intend to make any\n  more iPhone applications unless absolutely necessary.\n[4]\n\nCan anything break this cycle?  No device I've seen so far could.\nPalm and RIM haven't a hope.  The only credible contender is Android.\nBut Android is an orphan; Google doesn't really care about it, not\nthe way Apple cares about the iPhone.  Apple cares about the iPhone\nthe way Google cares about search.* * *Is the future of handheld devices one locked down by Apple?  It's\na worrying prospect.  It would be a bummer to have another grim\nmonoculture like we had in the 1990s.  In 1995, writing software\nfor end users was effectively identical with writing Windows\napplications.  Our horror at that prospect was the single biggest\nthing that drove us to start building web apps.At least we know now what it would take to break Apple's lock.\nYou'd have to get iPhones out of programmers' hands.  If programmers\nused some other device for mobile web access, they'd start to develop\napps for that instead.How could you make a device programmers liked better than the iPhone?\nIt's unlikely you could make something better designed.  Apple\nleaves no room there.  So this alternative device probably couldn't\nwin on general appeal.  It would have to win by virtue of some\nappeal it had to programmers specifically.One way to appeal to programmers is with software.  If you\ncould think of an application programmers had to have, but that\nwould be impossible in the circumscribed world of the iPhone, \nyou could presumably get them to switch.That would definitely happen if programmers started to use handhelds\nas development machines\u2014if handhelds displaced laptops the\nway laptops displaced desktops.  You need more control of a development\nmachine than Apple will let you have over an iPhone.Could anyone make a device that you'd carry around in your pocket\nlike a phone, and yet would also work as a development machine?\nIt's hard to imagine what it would look like.  But I've learned\nnever to say never about technology.  A phone-sized device that\nwould work as a development machine is no more miraculous by present\nstandards than the iPhone itself would have seemed by the standards\nof 1995.My current development machine is a MacBook Air, which I use with\nan external monitor and keyboard in my office, and by itself when\ntraveling.  If there was a version half the size I'd prefer it.\nThat still wouldn't be small enough to carry around everywhere like\na phone, but we're within a factor of 4 or so.  Surely that gap is\nbridgeable.  In fact, let's make it an\nRFS. Wanted: \nWoman with hammer.Notes[1]\nWhen Google adopted \"Don't be evil,\" they were still so small\nthat no one would have expected them to be, yet.\n[2]\nThe dictator in the 1984 ad isn't Microsoft, incidentally;\nit's IBM.  IBM seemed a lot more frightening in those days, but\nthey were friendlier to developers than Apple is now.[3]\nHe couldn't even afford a monitor.  That's why the Apple\nI used a TV as a monitor.[4]\nSeveral people I talked to mentioned how much they liked the\niPhone SDK.  The problem is not Apple's products but their policies.\nFortunately policies are software; Apple can change them instantly\nif they want to.  Handy that, isn't it?Thanks to Sam Altman, Trevor Blackwell, Ross Boucher, \nJames Bracy, Gabor Cselle,\nPatrick Collison, Jason Freedman, John Gruber, Joe Hewitt, Jessica Livingston,\nRobert Morris, Teng Siong Ong, Nikhil Pandit, Savraj Singh, and Jared Tame for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nApril 2001, rev. April 2003(This article is derived from a talk given at the 2001 Franz\nDeveloper Symposium.)\nIn the summer of 1995, my friend Robert Morris and I\nstarted a startup called \nViaweb.  \nOur plan was to write\nsoftware that would let end users build online stores.\nWhat was novel about this software, at the time, was\nthat it ran on our server, using ordinary Web pages\nas the interface.A lot of people could have been having this idea at the\nsame time, of course, but as far as I know, Viaweb was\nthe first Web-based application.  It seemed such\na novel idea to us that we named the company after it:\nViaweb, because our software worked via the Web,\ninstead of running on your desktop computer.Another unusual thing about this software was that it\nwas written primarily in a programming language called\nLisp. It was one of the first big end-user\napplications to be written in Lisp, which up till then\nhad been used mostly in universities and research labs. [1]The Secret WeaponEric Raymond has written an essay called \"How to Become a Hacker,\"\nand in it, among other things, he tells would-be hackers what\nlanguages they should learn.  He suggests starting with Python and\nJava, because they are easy to learn.  The serious hacker will also\nwant to learn C, in order to hack Unix, and Perl for system\nadministration and cgi scripts.  Finally, the truly serious hacker\nshould consider learning Lisp:\n\n  Lisp is worth learning for the profound enlightenment experience\n  you will have when you finally get it; that experience will make\n  you a better programmer for the rest of your days, even if you\n  never actually use Lisp itself a lot.\n\nThis is the same argument you tend to hear for learning Latin.  It\nwon't get you a job, except perhaps as a classics professor, but\nit will improve your mind, and make you a better writer in languages\nyou do want to use, like English.But wait a minute.  This metaphor doesn't stretch that far.  The\nreason Latin won't get you a job is that no one speaks it.  If you\nwrite in Latin, no one can understand you.  But Lisp is a computer\nlanguage, and computers speak whatever language you, the programmer,\ntell them to.So if Lisp makes you a better programmer, like he says, why wouldn't\nyou want to use it? If a painter were offered a brush that would\nmake him a better painter, it seems to me that he would want to\nuse it in all his paintings, wouldn't he? I'm not trying to make\nfun of Eric Raymond here.  On the whole, his advice is good.  What\nhe says about Lisp is pretty much the conventional wisdom.  But\nthere is a contradiction in the conventional wisdom:  Lisp will\nmake you a better programmer, and yet you won't use it.Why not?  Programming languages are just tools, after all.  If Lisp\nreally does yield better programs, you should use it.  And if it\ndoesn't, then who needs it?This is not just a theoretical question.  Software is a very\ncompetitive business, prone to natural monopolies.  A company that\ngets software written faster and better will, all other things\nbeing equal, put its competitors out of business.  And when you're\nstarting a startup, you feel this very keenly.  Startups tend to\nbe an all or nothing proposition.  You either get rich, or you get\nnothing.  In a startup, if you bet on the wrong technology, your\ncompetitors will crush you.Robert and I both knew Lisp well, and we couldn't see any reason\nnot to trust our instincts and go with Lisp.  We knew that everyone\nelse was writing their software in C++ or Perl.  But we also knew\nthat that didn't mean anything.  If you chose technology that way,\nyou'd be running Windows.  When you choose technology, you have to\nignore what other people are doing, and consider only what will\nwork the best.This is especially true in a startup.  In a big company, you can\ndo what all the other big companies are doing.  But a startup can't\ndo what all the other startups do.  I don't think a lot of people\nrealize this, even in startups.The average big company grows at about ten percent a year.  So if\nyou're running a big company and you do everything the way the\naverage big company does it, you can expect to do as well as the\naverage big company-- that is, to grow about ten percent a year.The same thing will happen if you're running a startup, of course.\nIf you do everything the way the average startup does it, you should\nexpect average performance.  The problem here is, average performance\nmeans that you'll go out of business.  The survival rate for startups\nis way less than fifty percent.  So if you're running a startup,\nyou had better be doing something odd.  If not, you're in trouble.Back in 1995, we knew something that I don't think our competitors\nunderstood, and few understand even now:  when you're writing\nsoftware that only has to run on your own servers, you can use\nany language you want.  When you're writing desktop software,\nthere's a strong bias toward writing applications in the same\nlanguage as the operating system.  Ten years ago, writing applications\nmeant writing applications in C.  But with Web-based software,\nespecially when you have the source code of both the language and\nthe operating system, you can use whatever language you want.This new freedom is a double-edged sword, however.  Now that you\ncan use any language, you have to think about which one to use.\nCompanies that try to pretend nothing has changed risk finding that\ntheir competitors do not.If you can use any language, which do you use?  We chose Lisp.\nFor one thing, it was obvious that rapid development would be\nimportant in this market.  We were all starting from scratch, so\na company that could get new features done before its competitors\nwould have a big advantage.  We knew Lisp was a really good language\nfor writing software quickly, and server-based applications magnify\nthe effect of rapid development, because you can release software\nthe minute it's done.If other companies didn't want to use Lisp, so much the better.\nIt might give us a technological edge, and we needed all the help\nwe could get.  When we started Viaweb, we had no experience in\nbusiness.  We didn't know anything about marketing, or hiring\npeople, or raising money, or getting customers.  Neither of us had\never even had what you would call a real job.  The only thing we\nwere good at was writing software.  We hoped that would save us.\nAny advantage we could get in the software department, we would\ntake.So you could say that using Lisp was an experiment.  Our hypothesis\nwas that if we wrote our software in Lisp, we'd be able to get\nfeatures done faster than our competitors, and also to do things\nin our software that they couldn't do.  And because Lisp was so\nhigh-level, we wouldn't need a big development team, so our costs\nwould be lower.  If this were so, we could offer a better product\nfor less money, and still make a profit.  We would end up getting\nall the users, and our competitors would get none, and eventually\ngo out of business.  That was what we hoped would happen, anyway.What were the results of this experiment?  Somewhat surprisingly,\nit worked.  We eventually had many competitors, on the order of\ntwenty to thirty of them, but none of their software could compete\nwith ours.  We had a wysiwyg online store builder that ran on the\nserver and yet felt like a desktop application.  Our competitors\nhad cgi scripts.  And we were always far ahead of them in features.\nSometimes, in desperation, competitors would try to introduce\nfeatures that we didn't have.  But with Lisp our development cycle\nwas so fast that we could sometimes duplicate a new feature within\na day or two of a competitor announcing it in a press release.  By\nthe time journalists covering the press release got round to calling\nus, we would have the new feature too.It must have seemed to our competitors that we had some kind of\nsecret weapon-- that we were decoding their Enigma traffic or\nsomething.  In fact we did have a secret weapon, but it was simpler\nthan they realized.  No one was leaking news of their features to\nus.   We were just able to develop software faster than anyone\nthought possible.When I was about nine I happened to get hold of a copy of The Day\nof the Jackal, by Frederick Forsyth.  The main character is an\nassassin who is hired to kill the president of France.  The assassin\nhas to get past the police to get up to an apartment that overlooks\nthe president's route.  He walks right by them, dressed up as an\nold man on crutches, and they never suspect him.Our secret weapon was similar.  We wrote our software in a weird\nAI language, with a bizarre syntax full of parentheses.  For years\nit had annoyed me to hear Lisp described that way.  But now it\nworked to our advantage.  In business, there is nothing more valuable\nthan a technical advantage your competitors don't understand.  In\nbusiness, as in war, surprise is worth as much as force.And so, I'm a little embarrassed to say, I never said anything\npublicly about Lisp while we were working on Viaweb.  We never\nmentioned it to the press, and if you searched for Lisp on our Web\nsite, all you'd find were the titles of two books in my bio.  This\nwas no accident.  A startup should give its competitors as little\ninformation as possible.  If they didn't know what language our\nsoftware was written in, or didn't care, I wanted to keep it that\nway.[2]The people who understood our technology best were the customers.\nThey didn't care what language Viaweb was written in either, but\nthey noticed that it worked really well.  It let them build great\nlooking online stores literally in minutes.  And so, by word of\nmouth mostly, we got more and more users.  By the end of 1996 we\nhad about 70 stores online.  At the end of 1997 we had 500.  Six\nmonths later, when Yahoo bought us, we had 1070 users.  Today, as\nYahoo Store, this software continues to dominate its market.  It's\none of the more profitable pieces of Yahoo, and the stores built\nwith it are the foundation of Yahoo Shopping.  I left Yahoo in\n1999, so I don't know exactly how many users they have now, but\nthe last I heard there were about 20,000.\nThe Blub ParadoxWhat's so great about Lisp?  And if Lisp is so great, why doesn't\neveryone use it?  These sound like rhetorical questions, but actually\nthey have straightforward answers.  Lisp is so great not because\nof some magic quality visible only to devotees, but because it is\nsimply the most powerful language available.  And the reason everyone\ndoesn't use it is that programming languages are not merely\ntechnologies, but habits of mind as well, and nothing changes\nslower.  Of course, both these answers need explaining.I'll begin with a shockingly controversial statement:  programming\nlanguages vary in power.Few would dispute, at least, that high level languages are more\npowerful than machine language.  Most programmers today would agree\nthat you do not, ordinarily, want to program in machine language.\nInstead, you should program in a high-level language, and have a\ncompiler translate it into machine language for you.  This idea is\neven built into the hardware now: since the 1980s, instruction sets\nhave been designed for compilers rather than human programmers.Everyone knows it's a mistake to write your whole program by hand\nin machine language.  What's less often understood is that there\nis a more general principle here: that if you have a choice of\nseveral languages, it is, all other things being equal, a mistake\nto program in anything but the most powerful one. [3]There are many exceptions to this rule.  If you're writing a program\nthat has to work very closely with a program written in a certain\nlanguage, it might be a good idea to write the new program in the\nsame language.  If you're writing a program that only has to do\nsomething very simple, like number crunching or bit manipulation,\nyou may as well use a less abstract language, especially since it\nmay be slightly faster.  And if you're writing a short, throwaway\nprogram, you may be better off just using whatever language has\nthe best library functions for the task.  But in general, for\napplication software, you want to be using the most powerful\n(reasonably efficient) language you can get, and using anything\nelse is a mistake, of exactly the same kind, though possibly in a\nlesser degree, as programming in machine language.You can see that machine language is very low level.  But, at least\nas a kind of social convention, high-level languages are often all\ntreated as equivalent.  They're not.  Technically the term \"high-level\nlanguage\" doesn't mean anything very definite.  There's no dividing\nline with machine languages on one side and all the high-level\nlanguages on the other.  Languages fall along a continuum [4] of\nabstractness, from the most powerful all the way down to machine\nlanguages, which themselves vary in power.Consider Cobol.  Cobol is a high-level language, in the sense that\nit gets compiled into machine language.  Would anyone seriously\nargue that Cobol is equivalent in power to, say, Python?  It's\nprobably closer to machine language than Python.Or how about Perl 4?  Between Perl 4 and Perl 5, lexical closures\ngot added to the language.  Most Perl hackers would agree that Perl\n5 is more powerful than Perl 4.  But once you've admitted that,\nyou've admitted that one high level language can be more powerful\nthan another.  And it follows inexorably that, except in special\ncases, you ought to use the most powerful you can get.This idea is rarely followed to its conclusion, though.  After a\ncertain age, programmers rarely switch languages voluntarily.\nWhatever language people happen to be used to, they tend to consider\njust good enough.Programmers get very attached to their favorite languages, and I\ndon't want to hurt anyone's feelings, so to explain this point I'm\ngoing to use a hypothetical language called Blub.  Blub falls right\nin the middle of the abstractness continuum.  It is not the most\npowerful language, but it is more powerful than Cobol or machine\nlanguage.And in fact, our hypothetical Blub programmer wouldn't use either\nof them.  Of course he wouldn't program in machine language.  That's\nwhat compilers are for.  And as for Cobol, he doesn't know how\nanyone can get anything done with it.  It doesn't even have x (Blub\nfeature of your choice).As long as our hypothetical Blub programmer is looking down the\npower continuum, he knows he's looking down.  Languages less powerful\nthan Blub are obviously less powerful, because they're missing some\nfeature he's used to.  But when our hypothetical Blub programmer\nlooks in the other direction, up the power continuum, he doesn't\nrealize he's looking up.  What he sees are merely weird languages.\nHe probably considers them about equivalent in power to Blub, but\nwith all this other hairy stuff thrown in as well.  Blub is good\nenough for him, because he thinks in Blub.When we switch to the point of view of a programmer using any of\nthe languages higher up the power continuum, however, we find that\nhe in turn looks down upon Blub.  How can you get anything done in\nBlub? It doesn't even have y.By induction, the only programmers in a position to see all the\ndifferences in power between the various languages are those who\nunderstand the most powerful one.  (This is probably what Eric\nRaymond meant about Lisp making you a better programmer.) You can't\ntrust the opinions of the others, because of the Blub paradox:\nthey're satisfied with whatever language they happen to use, because\nit dictates the way they think about programs.I know this from my own experience, as a high school kid writing\nprograms in Basic.  That language didn't even support recursion.\nIt's hard to imagine writing programs without using recursion, but\nI didn't miss it at the time.  I thought in Basic.  And I was a\nwhiz at it.  Master of all I surveyed.The five languages that Eric Raymond recommends to hackers fall at\nvarious points on the power continuum.  Where they fall relative\nto one another is a sensitive topic.  What I will say is that I\nthink Lisp is at the top.  And to support this claim I'll tell you\nabout one of the things I find missing when I look at the other\nfour languages.  How can you get anything done in them, I think,\nwithout macros? [5]Many languages have something called a macro.  But Lisp macros are\nunique.  And believe it or not, what they do is related to the\nparentheses.  The designers of Lisp didn't put all those parentheses\nin the language just to be different.  To the Blub programmer, Lisp\ncode looks weird.  But those parentheses are there for a reason.\nThey are the outward evidence of a fundamental difference between\nLisp and other languages.Lisp code is made out of Lisp data objects.  And not in the trivial\nsense that the source files contain characters, and strings are\none of the data types supported by the language.  Lisp code, after\nit's read by the parser, is made of data structures that you can\ntraverse.If you understand how compilers work, what's really going on is\nnot so much that Lisp has a strange syntax as that Lisp has no\nsyntax.  You write programs in the parse trees that get generated\nwithin the compiler when other languages are parsed.  But these\nparse trees are fully accessible to your programs.  You can write\nprograms that manipulate them.  In Lisp, these programs are called\nmacros.  They are programs that write programs.Programs that write programs?  When would you ever want to do that?\nNot very often, if you think in Cobol.  All the time, if you think\nin Lisp.  It would be convenient here if I could give an example\nof a powerful macro, and say there! how about that?  But if I did,\nit would just look like gibberish to someone who didn't know Lisp;\nthere isn't room here to explain everything you'd need to know to\nunderstand what it meant.  In \nAnsi Common Lisp I tried to move\nthings along as fast as I could, and even so I didn't get to macros\nuntil page 160.But I think I can give a kind of argument that might be convincing.\nThe source code of the Viaweb editor was probably about 20-25%\nmacros.  Macros are harder to write than ordinary Lisp functions,\nand it's considered to be bad style to use them when they're not\nnecessary.  So every macro in that code is there because it has to\nbe.  What that means is that at least 20-25% of the code in this\nprogram is doing things that you can't easily do in any other\nlanguage.  However skeptical the Blub programmer might be about my\nclaims for the mysterious powers of Lisp, this ought to make him\ncurious.  We weren't writing this code for our own amusement.  We\nwere a tiny startup, programming as hard as we could in order to\nput technical barriers between us and our competitors.A suspicious person might begin to wonder if there was some\ncorrelation here.  A big chunk of our code was doing things that\nare very hard to do in other languages.  The resulting software\ndid things our competitors' software couldn't do.  Maybe there was\nsome kind of connection.  I encourage you to follow that thread.\nThere may be more to that old man hobbling along on his crutches\nthan meets the eye.Aikido for StartupsBut I don't expect to convince anyone \n(over 25) \nto go out and learn\nLisp.  The purpose of this article is not to change anyone's mind,\nbut to reassure people already interested in using Lisp-- people\nwho know that Lisp is a powerful language, but worry because it\nisn't widely used.  In a competitive situation, that's an advantage.\nLisp's power is multiplied by the fact that your competitors don't\nget it.If you think of using Lisp in a startup, you shouldn't worry that\nit isn't widely understood.  You should hope that it stays that\nway. And it's likely to.  It's the nature of programming languages\nto make most people satisfied with whatever they currently use.\nComputer hardware changes so much faster than personal habits that\nprogramming practice is usually ten to twenty years behind the\nprocessor.  At places like MIT they were writing programs in\nhigh-level languages in the early 1960s, but many companies continued\nto write code in machine language well into the 1980s.  I bet a\nlot of people continued to write machine language until the processor,\nlike a bartender eager to close up and go home, finally kicked them\nout by switching to a risc instruction set.Ordinarily technology changes fast.  But programming languages are\ndifferent: programming languages are not just technology, but what\nprogrammers think in.  They're half technology and half religion.[6]\nAnd so the median language, meaning whatever language the median\nprogrammer uses, moves as slow as an iceberg.  Garbage collection,\nintroduced by Lisp in about 1960, is now widely considered to be\na good thing.  Runtime typing, ditto, is growing in popularity.\nLexical closures, introduced by Lisp in the early 1970s, are now,\njust barely, on the radar screen.  Macros, introduced by Lisp in the\nmid 1960s, are still terra incognita.Obviously, the median language has enormous momentum.  I'm not\nproposing that you can fight this powerful force.  What I'm proposing\nis exactly the opposite: that, like a practitioner of Aikido, you\ncan use it against your opponents.If you work for a big company, this may not be easy.  You will have\na hard time convincing the pointy-haired boss to let you build\nthings in Lisp, when he has just read in the paper that some other\nlanguage is poised, like Ada was twenty years ago, to take over\nthe world.  But if you work for a startup that doesn't have\npointy-haired bosses yet, you can, like we did, turn the Blub\nparadox to your advantage:  you can use technology that your\ncompetitors, glued immovably to the median language, will never be\nable to match.If you ever do find yourself working for a startup, here's a handy\ntip for evaluating competitors.  Read their job listings.  Everything\nelse on their site may be stock photos or the prose equivalent,\nbut the job listings have to be specific about what they want, or\nthey'll get the wrong candidates.During the years we worked on Viaweb I read a lot of job descriptions.\nA new competitor seemed to emerge out of the woodwork every month\nor so.  The first thing I would do, after checking to see if they\nhad a live online demo, was look at their job listings.  After a\ncouple years of this I could tell which companies to worry about\nand which not to.  The more of an IT flavor the job descriptions\nhad, the less dangerous the company was.  The safest kind were the\nones that wanted Oracle experience.  You never had to worry about\nthose.  You were also safe if they said they wanted C++ or Java\ndevelopers.  If they wanted Perl or Python programmers, that would\nbe a bit frightening-- that's starting to sound like a company\nwhere the technical side, at least, is run by real hackers.  If I\nhad ever seen a job posting looking for Lisp hackers, I would have\nbeen really worried.\nNotes[1] Viaweb at first had two parts: the editor, written in Lisp,\nwhich people used to build their sites, and the ordering system,\nwritten in C, which handled orders.  The first version was mostly\nLisp, because the ordering system was small.  Later we added two\nmore modules, an image generator written in C, and a back-office\nmanager written mostly in Perl.In January 2003, Yahoo released a new version of the editor \nwritten in C++ and Perl.  It's hard to say whether the program is no\nlonger written in Lisp, though, because to translate this program\ninto C++ they literally had to write a Lisp interpreter: the source\nfiles of all the page-generating templates are still, as far as I\nknow,  Lisp code.  (See Greenspun's Tenth Rule.)[2] Robert Morris says that I didn't need to be secretive, because\neven if our competitors had known we were using Lisp, they wouldn't\nhave understood why:  \"If they were that smart they'd already be\nprogramming in Lisp.\"[3] All languages are equally powerful in the sense of being Turing\nequivalent, but that's not the sense of the word programmers care\nabout. (No one wants to program a Turing machine.)  The kind of\npower programmers care about may not be formally definable, but\none way to explain it would be to say that it refers to features\nyou could only get in the less powerful language by writing an\ninterpreter for the more powerful language in it. If language A\nhas an operator for removing spaces from strings and language B\ndoesn't, that probably doesn't make A more powerful, because you\ncan probably write a subroutine to do it in B.  But if A supports,\nsay, recursion, and B doesn't, that's not likely to be something\nyou can fix by writing library functions.[4] Note to nerds: or possibly a lattice, narrowing toward the top;\nit's not the shape that matters here but the idea that there is at\nleast a partial order.[5] It is a bit misleading to treat macros as a separate feature.\nIn practice their usefulness is greatly enhanced by other Lisp\nfeatures like lexical closures and rest parameters.[6] As a result, comparisons of programming languages either take\nthe form of religious wars or undergraduate textbooks so determinedly\nneutral that they're really works of anthropology.  People who\nvalue their peace, or want tenure, avoid the topic.  But the question\nis only half a religious one; there is something there worth\nstudying, especially if you want to design new languages.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2014(This essay is derived from a guest lecture in Sam Altman's startup class at\nStanford.  It's intended for college students, but much of it is\napplicable to potential founders at other ages.)One of the advantages of having kids is that when you have to give\nadvice, you can ask yourself \"what would I tell my own kids?\"  My\nkids are little, but I can imagine what I'd tell them about startups\nif they were in college, and that's what I'm going to tell you.Startups are very counterintuitive.  I'm not sure why.  Maybe it's\njust because knowledge about them hasn't permeated our culture yet.\nBut whatever the reason, starting a startup is a task where you\ncan't always trust your instincts.It's like skiing in that way.  When you first try skiing and you\nwant to slow down, your instinct is to lean back.  But if you lean\nback on skis you fly down the hill out of control.  So part of\nlearning to ski is learning to suppress that impulse.  Eventually\nyou get new habits, but at first it takes a conscious effort.  At\nfirst there's a list of things you're trying to remember as you\nstart down the hill.Startups are as unnatural as skiing, so there's a similar list for\nstartups. Here I'm going to give you the first part of it \u2014 the things\nto remember if you want to prepare yourself to start a startup.\nCounterintuitiveThe first item on it is the fact I already mentioned: that startups\nare so weird that if you trust your instincts, you'll make a lot\nof mistakes.  If you know nothing more than this, you may at least\npause before making them.When I was running Y Combinator I used to joke that our function\nwas to tell founders things they would ignore.  It's really true.\nBatch after batch, the YC partners warn founders about mistakes\nthey're about to make, and the founders ignore them, and then come\nback a year later and say \"I wish we'd listened.\"Why do the founders ignore the partners' advice?  Well, that's the\nthing about counterintuitive ideas: they contradict your intuitions.\nThey seem wrong.  So of course your first impulse is to disregard\nthem.  And in fact my joking description is not merely the curse\nof Y Combinator but part of its raison d'etre. If founders' instincts\nalready gave them the right answers, they wouldn't need us.  You\nonly need other people to give you advice that surprises you. That's\nwhy there are a lot of ski instructors and not many running\ninstructors.\n[1]You can, however, trust your instincts about people.  And in fact\none of the most common mistakes young founders make is not to\ndo that enough.  They get involved with people who seem impressive,\nbut about whom they feel some misgivings personally.  Later when\nthings blow up they say \"I knew there was something off about him,\nbut I ignored it because he seemed so impressive.\"If you're thinking about getting involved with someone \u2014 as a\ncofounder, an employee, an investor, or an acquirer \u2014 and you\nhave misgivings about them, trust your gut.  If someone seems\nslippery, or bogus, or a jerk, don't ignore it.This is one case where it pays to be self-indulgent. Work with\npeople you genuinely like, and you've known long enough to be sure.\nExpertiseThe second counterintuitive point is that it's not that important\nto know a lot about startups.  The way to succeed in a startup is\nnot to be an expert on startups, but to be an expert on your users\nand the problem you're solving for them.\nMark Zuckerberg didn't succeed because he was an expert on startups.\nHe succeeded despite being a complete noob at startups, because he\nunderstood his users really well.If you don't know anything about, say, how to raise an angel round,\ndon't feel bad on that account.  That sort of thing you can learn\nwhen you need to, and forget after you've done it.In fact, I worry it's not merely unnecessary to learn in great\ndetail about the mechanics of startups, but possibly somewhat\ndangerous.  If I met an undergrad who knew all about convertible\nnotes and employee agreements and (God forbid) class FF stock, I\nwouldn't think \"here is someone who is way ahead of their peers.\"\nIt would set off alarms.  Because another of the characteristic\nmistakes of young founders is to go through the motions of starting\na startup.  They make up some plausible-sounding idea, raise money\nat a good valuation, rent a cool office, hire a bunch of people.\nFrom the outside that seems like what startups do.  But the next\nstep after rent a cool office and hire a bunch of people is: gradually\nrealize how completely fucked they are, because while imitating all\nthe outward forms of a startup they have neglected the one thing\nthat's actually essential: making something people want.\nGameWe saw this happen so often that we made up a name for it: playing\nhouse.  Eventually I realized why it was happening.  The reason\nyoung founders go through the motions of starting a startup is\nbecause that's what they've been trained to do for their whole lives\nup to that point.  Think about what you have to do to get into\ncollege, for example.  Extracurricular activities, check.  Even in\ncollege classes most of the work is as artificial as running laps.I'm not attacking the educational system for being this way. There\nwill always be a certain amount of fakeness in the work you do when\nyou're being taught something, and if you measure their performance\nit's inevitable that people will exploit the difference to the point\nwhere much of what you're measuring is artifacts of the fakeness.I confess I did it myself in college. I found that in a lot of\nclasses there might only be 20 or 30 ideas that were the right shape\nto make good exam questions.  The way I studied for exams in these\nclasses was not (except incidentally) to master the material taught\nin the class, but to make a list of potential exam questions and\nwork out the answers in advance. When I walked into the final, the\nmain thing I'd be feeling was curiosity about which of my questions\nwould turn up on the exam.  It was like a game.It's not surprising that after being trained for their whole lives\nto play such games, young founders' first impulse on starting a\nstartup is to try to figure out the tricks for winning at this new\ngame. Since fundraising appears to be the measure of success for\nstartups (another classic noob mistake), they always want to know what the\ntricks are for convincing investors.  We tell them the best way to\nconvince investors is to make a startup\nthat's actually doing well, meaning growing fast, and then simply\ntell investors so.  Then they want to know what the tricks are for\ngrowing fast.  And we have to tell them the best way to do that is\nsimply to make something people want.So many of the conversations YC partners have with young founders\nbegin with the founder asking \"How do we...\" and the partner replying\n\"Just...\"Why do the founders always make things so complicated?  The reason,\nI realized, is that they're looking for the trick.So this is the third counterintuitive thing to remember about\nstartups: starting a startup is where gaming the system stops\nworking.  Gaming the system may continue to work if you go to work\nfor a big company. Depending on how broken the company is, you can\nsucceed by sucking up to the right people, giving the impression\nof productivity, and so on. \n[2]\nBut that doesn't work with startups.\nThere is no boss to trick, only users, and all users care about is\nwhether your product does what they want. Startups are as impersonal\nas physics.  You have to make something people want, and you prosper\nonly to the extent you do.The dangerous thing is, faking does work to some degree on investors.\nIf you're super good at sounding like you know what you're talking\nabout, you can fool investors for at least one and perhaps even two\nrounds of funding.  But it's not in your interest to.  The company\nis ultimately doomed.  All you're doing is wasting your own time\nriding it down.So stop looking for the trick. There are tricks in startups, as\nthere are in any domain, but they are an order of magnitude less\nimportant than solving the real problem. A founder who knows nothing\nabout fundraising but has made something users love will have an\neasier time raising money than one who knows every trick in the\nbook but has a flat usage graph. And more importantly, the founder\nwho has made something users love is the one who will go on to\nsucceed after raising the money.Though in a sense it's bad news in that you're deprived of one of\nyour most powerful weapons, I think it's exciting that gaming the\nsystem stops working when you start a startup.  It's exciting that\nthere even exist parts of the world where you win by doing good\nwork.  Imagine how depressing the world would be if it were all\nlike school and big companies, where you either have to spend a lot\nof time on bullshit things or lose to people who do.\n[3]\nI would\nhave been delighted if I'd realized in college that there were parts\nof the real world where gaming the system mattered less than others,\nand a few where it hardly mattered at all.  But there are, and this\nvariation is one of the most important things to consider when\nyou're thinking about your future.  How do you win in each type of\nwork, and what would you like to win by doing?\n[4]\nAll-ConsumingThat brings us to our fourth counterintuitive point: startups are\nall-consuming.  If you start a startup, it will take over your life\nto a degree you cannot imagine.  And if your startup succeeds, it\nwill take over your life for a long time: for several years at the\nvery least, maybe for a decade, maybe for the rest of your working\nlife.  So there is a real opportunity cost here.Larry Page may seem to have an enviable life, but there are aspects\nof it that are unenviable.  Basically at 25 he started running as\nfast as he could and it must seem to him that he hasn't stopped to\ncatch his breath since.  Every day new shit happens in the Google\nempire that only the CEO can deal with, and he, as CEO, has to deal\nwith it.  If he goes on vacation for even a week, a whole week's\nbacklog of shit accumulates.  And he has to bear this uncomplainingly,\npartly because as the company's daddy he can never show fear or\nweakness, and partly because billionaires get less than zero sympathy\nif they talk about having difficult lives.  Which has the strange\nside effect that the difficulty of being a successful startup founder\nis concealed from almost everyone except those who've done it.Y Combinator has now funded several companies that can be called\nbig successes, and in every single case the founders say the same\nthing.  It never gets any easier.  The nature of the problems change.\nYou're worrying about construction delays at your London office\ninstead of the broken air conditioner in your studio apartment.\nBut the total volume of worry never decreases; if anything it\nincreases.Starting a successful startup is similar to having kids in that\nit's like a button you push that changes your life irrevocably.\nAnd while it's truly wonderful having kids, there are a lot of\nthings that are easier to do before you have them than after.  Many\nof which will make you a better parent when you do have kids. And\nsince you can delay pushing the button for a while, most people in\nrich countries do.Yet when it comes to startups, a lot of people seem to think they're\nsupposed to start them while they're still in college.  Are you\ncrazy?  And what are the universities thinking?  They go out of\ntheir way to ensure their students are well supplied with contraceptives,\nand yet they're setting up entrepreneurship programs and startup\nincubators left and right.To be fair, the universities have their hand forced here.  A lot\nof incoming students are interested in startups.  Universities are,\nat least de facto, expected to prepare them for their careers.  So\nstudents who want to start startups hope universities can teach\nthem about startups.  And whether universities can do this or not,\nthere's some pressure to claim they can, lest they lose applicants\nto other universities that do.Can universities teach students about startups?  Yes and no.  They\ncan teach students about startups, but as I explained before, this\nis not what you need to know.  What you need to learn about are the\nneeds of your own users, and you can't do that until you actually\nstart the company.\n[5]\nSo starting a startup is intrinsically\nsomething you can only really learn by doing it.  And it's impossible\nto do that in college, for the reason I just explained: startups\ntake over your life.  You can't start a startup for real as a\nstudent, because if you start a startup for real you're not a student\nanymore. You may be nominally a student for a bit, but you won't even\nbe that for long.\n[6]Given this dichotomy, which of the two paths should you take?  Be\na real student and not start a startup, or start a real startup and\nnot be a student?  I can answer that one for you. Do not start a\nstartup in college.  How to start a startup is just a subset of a\nbigger problem you're trying to solve: how to have a good life.\nAnd though starting a startup can be part of a good life for a lot\nof ambitious people, age 20 is not the optimal time to do it.\nStarting a startup is like a brutally fast depth-first search.  Most\npeople should still be searching breadth-first at 20.You can do things in your early 20s that you can't do as well before\nor after, like plunge deeply into projects on a whim and travel\nsuper cheaply with no sense of a deadline.  For unambitious people,\nthis sort of thing is the dreaded \"failure to launch,\" but for the\nambitious ones it can be an incomparably valuable sort of exploration.\nIf you start a startup at 20 and you're sufficiently successful,\nyou'll never get to do it.\n[7]Mark Zuckerberg will never get to bum around a foreign country.  He\ncan do other things most people can't, like charter jets to fly him\nto foreign countries. But success has taken a lot of the serendipity\nout of his life. Facebook is running him as much as he's running\nFacebook. And while it can be very cool to be in the grip of a\nproject you consider your life's work, there are advantages to\nserendipity too, especially early in life.  Among other things it\ngives you more options to choose your life's work from.There's not even a tradeoff here. You're not sacrificing anything\nif you forgo starting a startup at 20, because you're more likely\nto succeed if you wait.  In the unlikely case that you're 20 and\none of your side projects takes off like Facebook did, you'll face\na choice of running with it or not, and it may be reasonable to run\nwith it.  But the usual way startups take off is for the founders\nto make them take off, and it's gratuitously\nstupid to do that at 20.\nTryShould you do it at any age?  I realize I've made startups sound\npretty hard.  If I haven't, let me try again: starting a startup\nis really hard.  What if it's too hard?  How can you tell if you're\nup to this challenge?The answer is the fifth counterintuitive point: you can't tell. Your\nlife so far may have given you some idea what your prospects might\nbe if you tried to become a mathematician, or a professional football\nplayer.  But unless you've had a very strange life you haven't done\nmuch that was like being a startup founder.\nStarting a startup will change you a lot.  So what you're trying\nto estimate is not just what you are, but what you could grow into,\nand who can do that?For the past 9 years it was my job to predict whether people would\nhave what it took to start successful startups.  It was easy to\ntell how smart they were, and most people reading this will be over\nthat threshold.  The hard part was predicting how tough and ambitious they would become.  There\nmay be no one who has more experience at trying to predict that,\nso I can tell you how much an expert can know about it, and the\nanswer is: not much.  I learned to keep a completely open mind about\nwhich of the startups in each batch would turn out to be the stars.The founders sometimes think they know. Some arrive feeling sure\nthey will ace Y Combinator just as they've aced every one of the (few,\nartificial, easy) tests they've faced in life so far.  Others arrive\nwondering how they got in, and hoping YC doesn't discover whatever\nmistake caused it to accept them.  But there is little correlation\nbetween founders' initial attitudes and how well their companies\ndo.I've read that the same is true in the military \u2014 that the\nswaggering recruits are no more likely to turn out to be really\ntough than the quiet ones. And probably for the same reason: that\nthe tests involved are so different from the ones in their previous\nlives.If you're absolutely terrified of starting a startup, you probably\nshouldn't do it.  But if you're merely unsure whether you're up to\nit, the only way to find out is to try.  Just not now.\nIdeasSo if you want to start a startup one day, what should you do in\ncollege?  There are only two things you need initially: an idea and\ncofounders.  And the m.o. for getting both is the same.  Which leads\nto our sixth and last counterintuitive point: that the way to get\nstartup ideas is not to try to think of startup ideas.I've written a whole essay on this,\nso I won't repeat it all here.  But the short version is that if\nyou make a conscious effort to think of startup ideas, the ideas\nyou come up with will not merely be bad, but bad and plausible-sounding,\nmeaning you'll waste a lot of time on them before realizing they're\nbad.The way to come up with good startup ideas is to take a step back.\nInstead of making a conscious effort to think of startup ideas,\nturn your mind into the type that startup ideas form in without any\nconscious effort.  In fact, so unconsciously that you don't even\nrealize at first that they're startup ideas.This is not only possible, it's how Apple, Yahoo, Google, and\nFacebook all got started.  None of these companies were even meant\nto be companies at first.  They were all just side projects.  The\nbest startups almost have to start as side projects, because great\nideas tend to be such outliers that your conscious mind would reject\nthem as ideas for companies.Ok, so how do you turn your mind into the type that startup ideas\nform in unconsciously?  (1) Learn a lot about things that matter,\nthen (2) work on problems that interest you (3) with people you\nlike and respect.  The third part, incidentally, is how you get\ncofounders at the same time as the idea.The first time I wrote that paragraph, instead of \"learn a lot about\nthings that matter,\" I wrote \"become good at some technology.\" But\nthat prescription, though sufficient, is too narrow.  What was\nspecial about Brian Chesky and Joe Gebbia was not that they were\nexperts in technology.  They were good at design, and perhaps even\nmore importantly, they were good at organizing groups and making\nprojects happen.  So you don't have to work on technology per se,\nso long as you work on problems demanding enough to stretch you.What kind of problems are those?  That is very hard to answer in\nthe general case.  History is full of examples of young people who\nwere working on important problems that no\none else at the time thought were important, and in particular\nthat their parents didn't think were important.  On the other hand,\nhistory is even fuller of examples of parents who thought their\nkids were wasting their time and who were right.  So how do you\nknow when you're working on real stuff?\n[8]I know how I know.  Real problems are interesting, and I am\nself-indulgent in the sense that I always want to work on interesting\nthings, even if no one else cares about them (in fact, especially\nif no one else cares about them), and find it very hard to make\nmyself work on boring things, even if they're supposed to be\nimportant.My life is full of case after case where I worked on something just\nbecause it seemed interesting, and it turned out later to be useful\nin some worldly way.  Y\nCombinator itself was something I only did because it seemed\ninteresting. So I seem to have some sort of internal compass that\nhelps me out.  But I don't know what other people have in their\nheads. Maybe if I think more about this I can come up with heuristics\nfor recognizing genuinely interesting problems, but for the moment\nthe best I can offer is the hopelessly question-begging advice that\nif you have a taste for genuinely interesting problems, indulging\nit energetically is the best way to prepare yourself for a startup.\nAnd indeed, probably also the best way to live.\n[9]But although I can't explain in the general case what counts as an\ninteresting problem, I can tell you about a large subset of them.\nIf you think of technology as something that's spreading like a\nsort of fractal stain, every moving point on the edge represents\nan interesting problem.  So one guaranteed way to turn your mind\ninto the type that has good startup ideas is to get yourself to the\nleading edge of some technology \u2014 to cause yourself, as Paul\nBuchheit put it, to \"live in the future.\" When you reach that point,\nideas that will seem to other people uncannily prescient will seem\nobvious to you.  You may not realize they're startup ideas, but\nyou'll know they're something that ought to exist.For example, back at Harvard in the mid 90s a fellow grad student\nof my friends Robert and Trevor wrote his own voice over IP software.\nHe didn't mean it to be a startup, and he never tried to turn it\ninto one.  He just wanted to talk to his girlfriend in Taiwan without\npaying for long distance calls, and since he was an expert on\nnetworks it seemed obvious to him that the way to do it was turn\nthe sound into packets and ship it over the Internet. He never did\nany more with his software than talk to his girlfriend, but this\nis exactly the way the best startups get started.So strangely enough the optimal thing to do in college if you want\nto be a successful startup founder is not some sort of new, vocational\nversion of college focused on \"entrepreneurship.\" It's the classic\nversion of college as education for its own sake. If you want to\nstart a startup after college, what you should do in college is\nlearn powerful things.  And if you have genuine intellectual\ncuriosity, that's what you'll naturally tend to do if you just\nfollow your own inclinations.\n[10]The component of entrepreneurship that really matters is domain\nexpertise.  The way to become Larry Page was to become an expert\non search. And the way to become an expert on search was to be\ndriven by genuine curiosity, not some ulterior motive.At its best, starting a startup is merely an ulterior motive for\ncuriosity.  And you'll do it best if you introduce the ulterior\nmotive toward the end of the process.So here is the ultimate advice for young would-be startup founders,\nboiled down to two words: just learn.\nNotes[1]\nSome founders listen more than others, and this tends to be a\npredictor of success. One of the things I\nremember about the Airbnbs during YC is how intently they listened.[2]\nIn fact, this is one of the reasons startups are possible.  If\nbig companies weren't plagued by internal inefficiencies, they'd\nbe proportionately more effective, leaving less room for startups.[3]\nIn a startup you have to spend a lot of time on schleps, but this sort of work is merely\nunglamorous, not bogus.[4]\nWhat should you do if your true calling is gaming the system?\nManagement consulting.[5]\nThe company may not be incorporated, but if you start to get\nsignificant numbers of users, you've started it, whether you realize\nit yet or not.[6]\nIt shouldn't be that surprising that colleges can't teach\nstudents how to be good startup founders, because they can't teach\nthem how to be good employees either.The way universities \"teach\" students how to be employees is to\nhand off the task to companies via internship programs.  But you\ncouldn't do the equivalent thing for startups, because by definition\nif the students did well they would never come back.[7]\nCharles Darwin was 22 when he received an invitation to travel\naboard the HMS Beagle as a naturalist.  It was only because he was\notherwise unoccupied, to a degree that alarmed his family, that he\ncould accept it. And yet if he hadn't we probably would not know\nhis name.[8]\nParents can sometimes be especially conservative in this\ndepartment.  There are some whose definition of important problems\nincludes only those on the critical path to med school.[9]\nI did manage to think of a heuristic for detecting whether you\nhave a taste for interesting ideas: whether you find known boring\nideas intolerable.  Could you endure studying literary theory, or\nworking in middle management at a large company?[10]\nIn fact, if your goal is to start a startup, you can stick\neven more closely to the ideal of a liberal education than past\ngenerations have. Back when students focused mainly on getting a\njob after college, they thought at least a little about how the\ncourses they took might look to an employer.  And perhaps even\nworse, they might shy away from taking a difficult class lest they\nget a low grade, which would harm their all-important GPA.  Good\nnews: users don't care what your GPA\nwas.  And I've never heard of investors caring either.  Y Combinator\ncertainly never asks what classes you took in college or what grades\nyou got in them.\nThanks to Sam Altman, Paul Buchheit, John Collison, Patrick\nCollison, Jessica Livingston, Robert Morris, Geoff Ralston, and\nFred Wilson for reading drafts of this.October 2015This will come as a surprise to a lot of people, but in some cases\nit's possible to detect bias in a selection process without knowing\nanything about the applicant pool.  Which is exciting because among\nother things it means third parties can use this technique to detect\nbias whether those doing the selecting want them to or not.You can use this technique whenever (a) you have at least\na random sample of the applicants that were selected, (b) their\nsubsequent performance is measured, and (c) the groups of\napplicants you're comparing have roughly equal distribution of ability.How does it work?  Think about what it means to be biased.  What\nit means for a selection process to be biased against applicants\nof type x is that it's harder for them to make it through.  Which\nmeans applicants of type x have to be better to get selected than\napplicants not of type x.\n[1]\nWhich means applicants of type x\nwho do make it through the selection process will outperform other\nsuccessful applicants.  And if the performance of all the successful\napplicants is measured, you'll know if they do.Of course, the test you use to measure performance must be a valid\none.  And in particular it must not be invalidated by the bias you're\ntrying to measure.\nBut there are some domains where performance can be measured, and\nin those detecting bias is straightforward. Want to know if the\nselection process was biased against some type of applicant?  Check\nwhether they outperform the others.  This is not just a heuristic\nfor detecting bias.  It's what bias means.For example, many suspect that venture capital firms are biased\nagainst female founders. This would be easy to detect: among their\nportfolio companies, do startups with female founders outperform\nthose without?  A couple months ago, one VC firm (almost certainly\nunintentionally) published a study showing bias of this type. First\nRound Capital found that among its portfolio companies, startups\nwith female founders outperformed\nthose without by 63%. \n[2]The reason I began by saying that this technique would come as a\nsurprise to many people is that we so rarely see analyses of this\ntype.  I'm sure it will come as a surprise to First Round that they\nperformed one. I doubt anyone there realized that by limiting their\nsample to their own portfolio, they were producing a study not of\nstartup trends but of their own biases when selecting companies.I predict we'll see this technique used more in the future.  The\ninformation needed to conduct such studies is increasingly available.\nData about who applies for things is usually closely guarded by the\norganizations selecting them, but nowadays data about who gets\nselected is often publicly available to anyone who takes the trouble\nto aggregate it.\nNotes[1]\nThis technique wouldn't work if the selection process looked\nfor different things from different types of applicants\u2014for\nexample, if an employer hired men based on their ability but women\nbased on their appearance.[2]\nAs Paul Buchheit points out, First Round excluded their most \nsuccessful investment, Uber, from the study.  And while it \nmakes sense to exclude outliers from some types of studies, \nstudies of returns from startup investing, which is all about \nhitting outliers, are not one of them.\nThanks to Sam Altman, Jessica Livingston, and Geoff Ralston for reading\ndrafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nMarch 2008, rev. June 2008Technology tends to separate normal from natural.  Our bodies\nweren't designed to eat the foods that people in rich countries eat, or\nto get so little exercise.  \nThere may be a similar problem with the way we work: \na normal job may be as bad for us intellectually as white flour\nor sugar is for us physically.I began to suspect this after spending several years working \nwith startup founders.  I've now worked with over 200 of them, and I've\nnoticed a definite difference between programmers working on their\nown startups and those working for large organizations.\nI wouldn't say founders seem happier, necessarily;\nstarting a startup can be very stressful. Maybe the best way to put\nit is to say that they're happier in the sense that your body is\nhappier during a long run than sitting on a sofa eating\ndoughnuts.Though they're statistically abnormal, startup founders seem to be\nworking in a way that's more natural for humans.I was in Africa last year and saw a lot of animals in the wild that\nI'd only seen in zoos before. It was remarkable how different they\nseemed. Particularly lions. Lions in the wild seem about ten times\nmore alive. They're like different animals. I suspect that working\nfor oneself feels better to humans in much the same way that living\nin the wild must feel better to a wide-ranging predator like a lion.\nLife in a zoo is easier, but it isn't the life they were designed\nfor.\nTreesWhat's so unnatural about working for a big company?  The root of\nthe problem is that humans weren't meant to work in such large\ngroups.Another thing you notice when you see animals in the wild is that\neach species thrives in groups of a certain size.  A herd of impalas\nmight have 100 adults; baboons maybe 20; lions rarely 10.  Humans\nalso seem designed to work in groups, and what I've read about\nhunter-gatherers accords with research on organizations and my own\nexperience to suggest roughly what the ideal size is: groups of 8\nwork well; by 20 they're getting hard to manage; and a group of 50\nis really unwieldy.\n[1]\nWhatever the upper limit is, we are clearly not meant to work in\ngroups of several hundred.  And yet\u2014for reasons having more\nto do with technology than human nature\u2014a great many people\nwork for companies with hundreds or thousands of employees.Companies know groups that large wouldn't work, so they divide\nthemselves into units small enough to work together.  But to\ncoordinate these they have to introduce something new: bosses.These smaller groups are always arranged in a tree structure.  Your\nboss is the point where your group attaches to the tree.  But when\nyou use this trick for dividing a large group into smaller ones,\nsomething strange happens that I've never heard anyone mention\nexplicitly.  In the group one level up from yours, your boss\nrepresents your entire group.  A group of 10 managers is not merely\na group of 10 people working together in the usual way.  It's really\na group of groups.  Which means for a group of 10 managers to work\ntogether as if they were simply a group of 10 individuals, the group\nworking for each manager would have to work as if they were a single\nperson\u2014the workers and manager would each share only one\nperson's worth of freedom between them.In practice a group of people are never able to act as if they were\none person.  But in a large organization divided into groups in\nthis way, the pressure is always in that direction.  Each group\ntries its best to work as if it were the small group of individuals\nthat humans were designed to work in.  That was the point of creating\nit.  And when you propagate that constraint, the result is that\neach person gets freedom of action in inverse proportion to the\nsize of the entire tree.\n[2]Anyone who's worked for a large organization has felt this.  You\ncan feel the difference between working for a company with 100\nemployees and one with 10,000, even if your group has only 10 people.\nCorn SyrupA group of 10 people within a large organization is a kind of fake\ntribe.  The number of people you interact with is about right.  But\nsomething is missing: individual initiative.  Tribes of hunter-gatherers\nhave much more freedom.  The leaders have a little more power than other\nmembers of the tribe, but they don't generally tell them what to\ndo and when the way a boss can.It's not your boss's fault.  The real problem is that in the group\nabove you in the hierarchy, your entire group is one virtual person.\nYour boss is just the way that constraint is imparted to you.So working in a group of 10 people within a large organization feels\nboth right and wrong at the same time.   On the surface it feels\nlike the kind of group you're meant to work in, but something major\nis missing.  A job at a big company is like high fructose corn\nsyrup: it has some of the qualities of things you're meant to like,\nbut is disastrously lacking in others.Indeed, food is an excellent metaphor to explain what's wrong with\nthe usual sort of job.For example, working for a big company is the default thing to do,\nat least for programmers.  How bad could it be?  Well, food shows\nthat pretty clearly.  If you were dropped at a random point in\nAmerica today, nearly all the food around you would be bad for you.\nHumans were not designed to eat white flour, refined sugar, high\nfructose corn syrup, and hydrogenated vegetable oil.  And yet if\nyou analyzed the contents of the average grocery store you'd probably\nfind these four ingredients accounted for most of the calories.\n\"Normal\" food is terribly bad for you.  The only people who eat\nwhat humans were actually designed to eat are a few Birkenstock-wearing\nweirdos in Berkeley.If \"normal\" food is so bad for us, why is it so common?  There are\ntwo main reasons. One is that it has more immediate appeal.  You\nmay feel lousy an hour after eating that pizza, but eating the first\ncouple bites feels great.  The other is economies of scale.\nProducing junk food scales; producing fresh vegetables doesn't.\nWhich means (a) junk food can be very cheap, and (b) it's worth\nspending a lot to market it.If people have to choose between something that's cheap, heavily\nmarketed, and appealing in the short term, and something that's\nexpensive, obscure, and appealing in the long term, which do you\nthink most will choose?It's the same with work.  The average MIT graduate wants to work\nat Google or Microsoft, because it's a recognized brand, it's safe,\nand they'll get paid a good salary right away.  It's the job\nequivalent of the pizza they had for lunch.  The drawbacks will\nonly become apparent later, and then only in a vague sense of\nmalaise.And founders and early employees of startups, meanwhile, are like\nthe Birkenstock-wearing weirdos of Berkeley:  though a tiny minority\nof the population, they're the ones living as humans are meant to.\nIn an artificial world, only extremists live naturally.\nProgrammersThe restrictiveness of big company jobs is particularly hard on\nprogrammers, because the essence of programming is to build new\nthings.  Sales people make much the same pitches every day; support\npeople answer much the same questions; but once you've written a\npiece of code you don't need to write it again.  So a programmer\nworking as programmers are meant to is always making new things.\nAnd when you're part of an organization whose structure gives each\nperson freedom in inverse proportion to the size of the tree, you're\ngoing to face resistance when you do something new.This seems an inevitable consequence of bigness.  It's true even\nin the smartest companies.  I was talking recently to a founder who\nconsidered starting a startup right out of college, but went to\nwork for Google instead because he thought he'd learn more there.\nHe didn't learn as much as he expected.  Programmers learn by doing,\nand most of the things he wanted to do, he couldn't\u2014sometimes\nbecause the company wouldn't let him, but often because the company's\ncode wouldn't let him.  Between the drag of legacy code, the overhead\nof doing development in such a large organization, and the restrictions\nimposed by interfaces owned by other groups, he could only try a\nfraction of the things he would have liked to.  He said he has\nlearned much more in his own startup, despite the fact that he has\nto do all the company's errands as well as programming, because at\nleast when he's programming he can do whatever he wants.An obstacle downstream propagates upstream.  If you're not allowed\nto implement new ideas, you stop having them.  And vice versa: when\nyou can do whatever you want, you have more ideas about what to do.\nSo working for yourself makes your brain more powerful in the same\nway a low-restriction exhaust system makes an engine more powerful.Working for yourself doesn't have to mean starting a startup, of\ncourse.  But a programmer deciding between a regular job at a big\ncompany and their own startup is probably going to learn more doing\nthe startup.You can adjust the amount of freedom you get by scaling the size\nof company you work for.  If you start the company, you'll have the\nmost freedom.  If you become one of the first 10 employees you'll\nhave almost as much freedom as the founders.  Even a company with\n100 people will feel different from one with 1000.Working for a small company doesn't ensure freedom.  The tree\nstructure of large organizations sets an upper bound on freedom,\nnot a lower bound.  The head of a small company may still choose\nto be a tyrant.  The point is that a large organization is compelled\nby its structure to be one.\nConsequencesThat has real consequences for both organizations and individuals.\nOne is that companies will inevitably slow down as they grow larger,\nno matter how hard they try to keep their startup mojo.  It's a\nconsequence of the tree structure that every large organization is\nforced to adopt.Or rather, a large organization could only avoid slowing down if\nthey avoided tree structure.  And since human nature limits the\nsize of group that can work together, the only way I can imagine\nfor larger groups to avoid tree structure would be to have no\nstructure: to have each group actually be independent, and to work\ntogether the way components of a market economy do.That might be worth exploring.  I suspect there are already some\nhighly partitionable businesses that lean this way.  But I don't\nknow any technology companies that have done it.There is one thing companies can do short of structuring themselves\nas sponges:  they can stay small.  If I'm right, then it really\npays to keep a company as small as it can be at every stage.\nParticularly a technology company.  Which means it's doubly important\nto hire the best people.  Mediocre hires hurt you twice: they get\nless done, but they also make you big, because you need more of\nthem to solve a given problem.For individuals the upshot is the same: aim small.  It will always\nsuck to work for large organizations, and the larger the organization,\nthe more it will suck.In an essay I wrote a couple years ago \nI advised graduating seniors\nto work for a couple years for another company before starting their\nown.  I'd modify that now.  Work for another company if you want\nto, but only for a small one, and if you want to start your own\nstartup, go ahead.The reason I suggested college graduates not start startups immediately\nwas that I felt most would fail.  And they will.  But ambitious\nprogrammers are better off doing their own thing and failing than\ngoing to work at a big company.  Certainly they'll learn more.  They\nmight even be better off financially.  A lot of people in their\nearly twenties get into debt, because their expenses grow even\nfaster than the salary that seemed so high when they left school.\nAt least if you start a startup and fail your net worth will be\nzero rather than negative.  \n[3]We've now funded so many different types of founders that we have\nenough data to see patterns, and there seems to be no benefit from\nworking for a big company.  The people who've worked for a few years\ndo seem better than the ones straight out of college, but only\nbecause they're that much older.The people who come to us from big companies often seem kind of\nconservative.  It's hard to say how much is because big companies\nmade them that way, and how much is the natural conservatism that\nmade them work for the big companies in the first place.  But\ncertainly a large part of it is learned.  I know because I've seen\nit burn off.Having seen that happen so many times is one of the things that\nconvinces me that working for oneself, or at least for a small\ngroup, is the natural way for programmers to live.  Founders arriving\nat Y Combinator often have the downtrodden air of refugees.  Three\nmonths later they're transformed: they have so much more \nconfidence\nthat they seem as if they've grown several inches taller. \n[4]\nStrange as this sounds, they seem both more worried and happier at the same\ntime.  Which is exactly how I'd describe the way lions seem in the\nwild.Watching employees get transformed into founders makes it clear\nthat the difference between the two is due mostly to environment\u2014and\nin particular that the environment in big companies is toxic to\nprogrammers.   In the first couple weeks of working on their own\nstartup they seem to come to life, because finally they're working\nthe way people are meant to.Notes[1]\nWhen I talk about humans being meant or designed to live a\ncertain way, I mean by evolution.[2]\nIt's not only the leaves who suffer.  The constraint propagates\nup as well as down.  So managers are constrained too; instead of\njust doing things, they have to act through subordinates.[3]\nDo not finance your startup with credit cards.  Financing a\nstartup with debt is usually a stupid move, and credit card debt\nstupidest of all.  Credit card debt is a bad idea, period.  It is\na trap set by evil companies for the desperate and the foolish.[4]\nThe founders we fund used to be younger (initially we encouraged\nundergrads to apply), and the first couple times I saw this I used\nto wonder if they were actually getting physically taller.Thanks to Trevor Blackwell, Ross Boucher, Aaron Iba, Abby\nKirigin, Ivan Kirigin, Jessica Livingston, and Robert Morris for\nreading drafts of this.July 2006\nWhen I was in high school I spent a lot of time imitating bad\nwriters.  What we studied in English classes was mostly fiction,\nso I assumed that was the highest form of writing.  Mistake number\none.  The stories that seemed to be most admired were ones in which\npeople suffered in complicated ways.  Anything funny or\ngripping was ipso facto suspect, unless it was old enough to be hard to\nunderstand, like Shakespeare or Chaucer.  Mistake number two.  The\nideal medium seemed the short story, which I've since learned had\nquite a brief life, roughly coincident with the peak of magazine\npublishing.  But since their size made them perfect for use in\nhigh school classes, we read a lot of them, which gave us the\nimpression the short story was flourishing.  Mistake number three.\nAnd because they were so short, nothing really had to happen; you\ncould just show a randomly truncated slice of life, and that was\nconsidered advanced.  Mistake number four.  The result was that I\nwrote a lot of stories in which nothing happened except that someone\nwas unhappy in a way that seemed deep.For most of college I was a philosophy major.  I was very impressed\nby the papers published in philosophy journals.  They were so\nbeautifully typeset, and their tone was just captivating\u2014alternately\ncasual and buffer-overflowingly technical.  A fellow would be walking\nalong a street and suddenly modality qua modality would spring upon\nhim.  I didn't ever quite understand these papers, but I figured\nI'd get around to that later, when I had time to reread them more\nclosely.  In the meantime I tried my best to imitate them.  This\nwas, I can now see, a doomed undertaking, because they weren't\nreally saying anything.  No philosopher ever refuted another, for\nexample, because no one said anything definite enough to refute.\nNeedless to say, my imitations didn't say anything either.In grad school I was still wasting time imitating the wrong things.\nThere was then a fashionable type of program called an expert system,\nat the core of which was something called an inference engine.  I\nlooked at what these things did and thought \"I could write that in\na thousand lines of code.\"  And yet eminent professors were writing\nbooks about them, and startups were selling them for a year's salary\na copy.  What an opportunity, I thought; these impressive things\nseem easy to me; I must be pretty sharp.  Wrong.  It was simply a\nfad.  The books the professors wrote about expert systems are now\nignored.  They were not even on a path to anything interesting.\nAnd the customers paying so much for them were largely the same\ngovernment agencies that paid thousands for screwdrivers and toilet\nseats.How do you avoid copying the wrong things?  Copy only what you\ngenuinely like.  That would have saved me in all three cases.  I\ndidn't enjoy the short stories we had to read in English classes;\nI didn't learn anything from philosophy papers; I didn't use expert\nsystems myself.  I believed these things were good because they\nwere admired.It can be hard to separate the things you like from the things\nyou're impressed with.  One trick is to ignore presentation.  Whenever\nI see a painting impressively hung in a museum, I ask myself: how\nmuch would I pay for this if I found it at a garage sale, dirty and\nframeless, and with no idea who painted it?  If you walk around a\nmuseum trying this experiment, you'll find you get some truly\nstartling results.  Don't ignore this data point just because it's\nan outlier.Another way to figure out what you like is to look at what you enjoy\nas guilty pleasures.  Many things people like, especially if they're\nyoung and ambitious, they like largely for the feeling of virtue\nin liking them.  99% of people reading Ulysses are thinking\n\"I'm reading Ulysses\" as they do it. A guilty pleasure is\nat least a pure one.  What do you read when you don't feel up to being\nvirtuous?  What kind of book do you read and feel sad that there's\nonly half of it left, instead of being impressed that you're half\nway through?  That's what you really like.Even when you find genuinely good things to copy, there's another\npitfall to be avoided.  Be careful to copy what makes them good,\nrather than their flaws.  It's easy to be drawn into imitating\nflaws, because they're easier to see, and of course easier to copy\ntoo.  For example, most painters in the eighteenth and nineteenth\ncenturies used brownish colors.  They were imitating the great\npainters of the Renaissance, whose paintings by that time were brown\nwith dirt.  Those paintings have since been cleaned, revealing\nbrilliant colors; their imitators are of course still brown.It was painting, incidentally, that cured me of copying the wrong\nthings.  Halfway through grad school I decided I wanted to try being\na painter, and the art world was so manifestly corrupt that it\nsnapped the leash of credulity.  These people made philosophy\nprofessors seem as scrupulous as mathematicians.  It was so clearly\na choice of doing good work xor being an insider that I was forced\nto see the distinction.  It's there to some degree in almost every\nfield, but I had till then managed to avoid facing it.That was one of the most valuable things I learned from painting:\nyou have to figure out for yourself what's \ngood.  You can't trust\nauthorities. They'll lie to you on this one.\n\nComment on this essay.January 2015Corporate Development, aka corp dev, is the group within companies\nthat buys other companies. If you're talking to someone from corp\ndev, that's why, whether you realize it yet or not.It's usually a mistake to talk to corp dev unless (a) you want to\nsell your company right now and (b) you're sufficiently likely to\nget an offer at an acceptable price.  In practice that means startups\nshould only talk to corp dev when they're either doing really well\nor really badly.  If you're doing really badly, meaning the company\nis about to die, you may as well talk to them, because you have\nnothing to lose. And if you're doing really well, you can safely\ntalk to them, because you both know the price will have to be high,\nand if they show the slightest sign of wasting your time, you'll\nbe confident enough to tell them to get lost.The danger is to companies in the middle.  Particularly to young\ncompanies that are growing fast, but haven't been doing it for long\nenough to have grown big yet.  It's usually a mistake for a promising\ncompany less than a year old even to talk to corp dev.But it's a mistake founders constantly make.  When someone from\ncorp dev wants to meet, the founders tell themselves they should\nat least find out what they want.  Besides, they don't want to\noffend Big Company by refusing to meet.Well, I'll tell you what they want.  They want to talk about buying\nyou.  That's what the title \"corp dev\" means.   So before agreeing\nto meet with someone from corp dev, ask yourselves, \"Do we want to\nsell the company right now?\"  And if the answer is no, tell them\n\"Sorry, but we're focusing on growing the company.\"  They won't be\noffended.  And certainly the founders of Big Company won't be\noffended. If anything they'll think more highly of you.  You'll\nremind them of themselves.  They didn't sell either; that's why\nthey're in a position now to buy other companies.\n[1]Most founders who get contacted by corp dev already know what it\nmeans.  And yet even when they know what corp dev does and know\nthey don't want to sell, they take the meeting.  Why do they do it?\nThe same mix of denial and wishful thinking that underlies most\nmistakes founders make. It's flattering to talk to someone who wants\nto buy you.  And who knows, maybe their offer will be surprisingly\nhigh.  You should at least see what it is, right?No.  If they were going to send you an offer immediately by email,\nsure, you might as well open it.  But that is not how conversations\nwith corp dev work.  If you get an offer at all, it will be at the\nend of a long and unbelievably distracting process.  And if the\noffer is surprising, it will be surprisingly low.Distractions are the thing you can least afford in a startup.  And\nconversations with corp dev are the worst sort of distraction,\nbecause as well as consuming your attention they undermine your\nmorale.  One of the tricks to surviving a grueling process is not\nto stop and think how tired you are.  Instead you get into a sort\nof flow. \n[2]\nImagine what it would do to you if at mile 20 of a\nmarathon, someone ran up beside you and said \"You must feel really\ntired.  Would you like to stop and take a rest?\"  Conversations\nwith corp dev are like that but worse, because the suggestion of\nstopping gets combined in your mind with the imaginary high price\nyou think they'll offer.And then you're really in trouble.  If they can, corp dev people\nlike to turn the tables on you. They like to get you to the point\nwhere you're trying to convince them to buy instead of them trying\nto convince you to sell.  And surprisingly often they succeed.This is a very slippery slope, greased with some of the most powerful\nforces that can work on founders' minds, and attended by an experienced\nprofessional whose full time job is to push you down it.Their tactics in pushing you down that slope are usually fairly\nbrutal. Corp dev people's whole job is to buy companies, and they\ndon't even get to choose which.  The only way their performance is\nmeasured is by how cheaply they can buy you, and the more ambitious\nones will stop at nothing to achieve that. For example, they'll\nalmost always start with a lowball offer, just to see if you'll\ntake it. Even if you don't, a low initial offer will demoralize you\nand make you easier to manipulate.And that is the most innocent of their tactics. Just wait till\nyou've agreed on a price and think you have a done deal, and then\nthey come back and say their boss has vetoed the deal and won't do\nit for more than half the agreed upon price. Happens all the time.\nIf you think investors can behave badly, it's nothing compared to\nwhat corp dev people can do.  Even corp dev people at companies\nthat are otherwise benevolent.I remember once complaining to a\nfriend at Google about some nasty trick their corp dev people had\npulled on a YC startup.\"What happened to Don't be Evil?\" I asked.\"I don't think corp dev got the memo,\" he replied.The tactics you encounter in M&A conversations can be like nothing\nyou've experienced in the otherwise comparatively \nupstanding world\nof Silicon Valley.  It's as if a chunk of genetic material from the\nold-fashioned robber baron business world got incorporated into the\nstartup world.\n[3]The simplest way to protect yourself is to use the trick that John\nD. Rockefeller, whose grandfather was an alcoholic, used to protect\nhimself from becoming one.  He once told a Sunday school class\n\n  Boys, do you know why I never became a drunkard?  Because I never\n  took the first drink.\n\nDo you want to sell your company right now?  Not eventually, right\nnow.  If not, just don't take the first meeting.  They won't be\noffended.  And you in turn will be guaranteed to be spared one of\nthe worst experiences that can happen to a startup.If you do want to sell, there's another set of \ntechniques\n for doing\nthat.  But the biggest mistake founders make in dealing with corp\ndev is not doing a bad job of talking to them when they're ready\nto, but talking to them before they are.  So if you remember only\nthe title of this essay, you already know most of what you need to\nknow about M&A in the first year.Notes[1]\nI'm not saying you should never sell.  I'm saying you should\nbe clear in your own mind about whether you want to sell or not,\nand not be led by manipulation or wishful thinking into trying to\nsell earlier than you otherwise would have.[2]\nIn a startup, as in most competitive sports, the task at hand\nalmost does this for you; you're too busy to feel tired.  But when\nyou lose that protection, e.g. at the final whistle, the fatigue\nhits you like a wave.  To talk to corp dev is to let yourself feel\nit mid-game.[3]\nTo be fair, the apparent misdeeds of corp dev people are magnified\nby the fact that they function as the face of a large organization\nthat often doesn't know its own mind.  Acquirers can be surprisingly\nindecisive about acquisitions, and their flakiness is indistinguishable\nfrom dishonesty by the time it filters down to you.Thanks to Marc Andreessen, Jessica Livingston, Geoff\nRalston, and Qasar Younis for reading drafts of this.January 2003(This article is derived from a keynote talk at the fall 2002 meeting\nof NEPLS.)Visitors to this country are often surprised to find that\nAmericans like to begin a conversation by asking \"what do you do?\"\nI've never liked this question.  I've rarely had a\nneat answer to it.  But I think I have finally solved the problem.\nNow, when someone asks me what I do, I look them straight\nin the eye and say \"I'm designing a \nnew dialect of Lisp.\"   \nI recommend this answer to anyone who doesn't like being asked what\nthey do.  The conversation will turn immediately to other topics.I don't consider myself to be doing research on programming languages.\nI'm just designing one, in the same way that someone might design\na building or a chair or a new typeface.\nI'm not trying to discover anything new.  I just want\nto make a language that will be good to program in.  In some ways,\nthis assumption makes life a lot easier.The difference between design and research seems to be a question\nof new versus good.  Design doesn't have to be new, but it has to  \nbe good.  Research doesn't have to be good, but it has to be new.\nI think these two paths converge at the top: the best design\nsurpasses its predecessors by using new ideas, and the best research\nsolves problems that are not only new, but actually worth solving.\nSo ultimately we're aiming for the same destination, just approaching\nit from different directions.What I'm going to talk about today is what your target looks like\nfrom the back.  What do you do differently when you treat\nprogramming languages as a design problem instead of a research topic?The biggest difference is that you focus more on the user.\nDesign begins by asking, who is this\nfor and what do they need from it?  A good architect,\nfor example, does not begin by creating a design that he then\nimposes on the users, but by studying the intended users and figuring\nout what they need.Notice I said \"what they need,\" not \"what they want.\"  I don't mean\nto give the impression that working as a designer means working as \na sort of short-order cook, making whatever the client tells you\nto.  This varies from field to field in the arts, but\nI don't think there is any field in which the best work is done by\nthe people who just make exactly what the customers tell them to.The customer is always right in\nthe sense that the measure of good design is how well it works\nfor the user.  If you make a novel that bores everyone, or a chair\nthat's horribly uncomfortable to sit in, then you've done a bad\njob, period.  It's no defense to say that the novel or the chair  \nis designed according to the most advanced theoretical principles.And yet, making what works for the user doesn't mean simply making\nwhat the user tells you to.  Users don't know what all the choices\nare, and are often mistaken about what they really want.The answer to the paradox, I think, is that you have to design\nfor the user, but you have to design what the user needs, not simply  \nwhat he says he wants.\nIt's much like being a doctor.  You can't just treat a patient's\nsymptoms.  When a patient tells you his symptoms, you have to figure\nout what's actually wrong with him, and treat that.This focus on the user is a kind of axiom from which most of the\npractice of good design can be derived, and around which most design\nissues center.If good design must do what the user needs, who is the user?  When\nI say that design must be for users, I don't mean to imply that good \ndesign aims at some kind of  \nlowest common denominator.  You can pick any group of users you\nwant.  If you're designing a tool, for example, you can design it\nfor anyone from beginners to experts, and what's good design\nfor one group might be bad for another.  The point\nis, you have to pick some group of users.  I don't think you can\neven talk about good or bad design except with\nreference to some intended user.You're most likely to get good design if the intended users include\nthe designer himself.  When you design something\nfor a group that doesn't include you, it tends to be for people\nyou consider to be less sophisticated than you, not more sophisticated.That's a problem, because looking down on the user, however benevolently,\nseems inevitably to corrupt the designer.\nI suspect that very few housing\nprojects in the US were designed by architects who expected to live\nin them.   You can see the same thing\nin programming languages.  C, Lisp, and Smalltalk were created for\ntheir own designers to use.  Cobol, Ada, and Java, were created   \nfor other people to use.If you think you're designing something for idiots, the odds are\nthat you're not designing something good, even for idiots.\nEven if you're designing something for the most sophisticated\nusers, though, you're still designing for humans.  It's different \nin research.  In math you\ndon't choose abstractions because they're\neasy for humans to understand; you choose whichever make the\nproof shorter.  I think this is true for the sciences generally.\nScientific ideas are not meant to be ergonomic.Over in the arts, things are very different.  Design is\nall about people.  The human body is a strange\nthing, but when you're designing a chair,\nthat's what you're designing for, and there's no way around it.\nAll the arts have to pander to the interests and limitations\nof humans.   In painting, for example, all other things being\nequal a painting with people in it will be more interesting than\none without.  It is not merely an accident of history that\nthe great paintings of the Renaissance are all full of people.\nIf they hadn't been, painting as a medium wouldn't have the prestige\nthat it does.Like it or not, programming languages are also for people,\nand I suspect the human brain is just as lumpy and idiosyncratic\nas the human body.  Some ideas are easy for people to grasp\nand some aren't.  For example, we seem to have a very limited\ncapacity for dealing with detail.  It's this fact that makes\nprograming languages a good idea in the first place; if we\ncould handle the detail, we could just program in machine\nlanguage.Remember, too, that languages are not\nprimarily a form for finished programs, but something that\nprograms have to be developed in.  Anyone in the arts could\ntell you that you might want different mediums for the\ntwo situations.  Marble, for example, is a nice, durable\nmedium for finished ideas, but a hopelessly inflexible one\nfor developing new ideas.A program, like a proof,\nis a pruned version of a tree that in the past has had\nfalse starts branching off all over it.  So the test of\na language is not simply how clean the finished program looks\nin it, but how clean the path to the finished program was.\nA design choice that gives you elegant finished programs\nmay not give you an elegant design process.  For example, \nI've written a few macro-defining macros full of nested\nbackquotes that look now like little gems, but writing them\ntook hours of the ugliest trial and error, and frankly, I'm still\nnot entirely sure they're correct.We often act as if the test of a language were how good\nfinished programs look in it.\nIt seems so convincing when you see the same program\nwritten in two languages, and one version is much shorter.\nWhen you approach the problem from the direction of the\narts, you're less likely to depend on this sort of\ntest.  You don't want to end up with a programming\nlanguage like marble.For example, it is a huge win in developing software to\nhave an interactive toplevel, what in Lisp is called a\nread-eval-print loop.  And when you have one this has\nreal effects on the design of the language.  It would not\nwork well for a language where you have to declare\nvariables before using them, for example.  When you're\njust typing expressions into the toplevel, you want to be \nable to set x to some value and then start doing things\nto x.  You don't want to have to declare the type of x\nfirst.  You may dispute either of the premises, but if\na language has to have a toplevel to be convenient, and\nmandatory type declarations are incompatible with a\ntoplevel, then no language that makes type declarations  \nmandatory could be convenient to program in.In practice, to get good design you have to get close, and stay\nclose, to your users.  You have to calibrate your ideas on actual\nusers constantly, especially in the beginning.  One of the reasons\nJane Austen's novels are so good is that she read them out loud to\nher family.  That's why she never sinks into self-indulgently arty\ndescriptions of landscapes,\nor pretentious philosophizing.  (The philosophy's there, but it's\nwoven into the story instead of being pasted onto it like a label.)\nIf you open an average \"literary\" novel and imagine reading it out loud\nto your friends as something you'd written, you'll feel all too\nkeenly what an imposition that kind of thing is upon the reader.In the software world, this idea is known as Worse is Better.\nActually, there are several ideas mixed together in the concept of\nWorse is Better, which is why people are still arguing about\nwhether worse\nis actually better or not.  But one of the main ideas in that\nmix is that if you're building something new, you should get a\nprototype in front of users as soon as possible.The alternative approach might be called the Hail Mary strategy.\nInstead of getting a prototype out quickly and gradually refining\nit, you try to create the complete, finished, product in one long\ntouchdown pass.  As far as I know, this is a\nrecipe for disaster.  Countless startups destroyed themselves this\nway during the Internet bubble.  I've never heard of a case\nwhere it worked.What people outside the software world may not realize is that\nWorse is Better is found throughout the arts.\nIn drawing, for example, the idea was discovered during the\nRenaissance.  Now almost every drawing teacher will tell you that\nthe right way to get an accurate drawing is not to\nwork your way slowly around the contour of an object, because errors will\naccumulate and you'll find at the end that the lines don't meet.\nInstead you should draw a few quick lines in roughly the right place,\nand then gradually refine this initial sketch.In most fields, prototypes\nhave traditionally been made out of different materials.\nTypefaces to be cut in metal were initially designed  \nwith a brush on paper.  Statues to be cast in bronze   \nwere modelled in wax.  Patterns to be embroidered on tapestries\nwere drawn on paper with ink wash.  Buildings to be\nconstructed from stone were tested on a smaller scale in wood.What made oil paint so exciting, when it\nfirst became popular in the fifteenth century, was that you\ncould actually make the finished work from the prototype.\nYou could make a preliminary drawing if you wanted to, but you\nweren't held to it; you could work out all the details, and\neven make major changes, as you finished the painting.You can do this in software too.  A prototype doesn't have to\nbe just a model; you can refine it into the finished product.\nI think you should always do this when you can.  It lets you\ntake advantage of new insights you have along the way.  But\nperhaps even more important, it's good for morale.Morale is key in design.  I'm surprised people\ndon't talk more about it.  One of my first\ndrawing teachers told me: if you're bored when you're\ndrawing something, the drawing will look boring.\nFor example, suppose you have to draw a building, and you\ndecide to draw each brick individually.  You can do this\nif you want, but if you get bored halfway through and start\nmaking the bricks mechanically instead of observing each one,   \nthe drawing will look worse than if you had merely suggested\nthe bricks.Building something by gradually refining a prototype is good\nfor morale because it keeps you engaged.  In software, my  \nrule is: always have working code.  If you're writing\nsomething that you'll be able to test in an hour, then you\nhave the prospect of an immediate reward to motivate you.\nThe same is true in the arts, and particularly in oil painting.\nMost painters start with a blurry sketch and gradually\nrefine it.\nIf you work this way, then in principle\nyou never have to end the day with something that actually\nlooks unfinished.  Indeed, there is even a saying among\npainters: \"A painting is never finished, you just stop\nworking on it.\"  This idea will be familiar to anyone who\nhas worked on software.Morale is another reason that it's hard to design something\nfor an unsophisticated user.   It's hard to stay interested in\nsomething you don't like yourself.  To make something  \ngood, you have to be thinking, \"wow, this is really great,\"\nnot \"what a piece of shit; those fools will love it.\"Design means making things for humans.  But it's not just the\nuser who's human.  The designer is human too.Notice all this time I've been talking about \"the designer.\"\nDesign usually has to be under the control of a single person to\nbe any good.   And yet it seems to be possible for several people\nto collaborate on a research project.  This seems to\nme one of the most interesting differences between research and\ndesign.There have been famous instances of collaboration in the arts,\nbut most of them seem to have been cases of molecular bonding rather\nthan nuclear fusion.  In an opera it's common for one person to\nwrite the libretto and another to write the music.   And during the Renaissance, \njourneymen from northern\nEurope were often employed to do the landscapes in the\nbackgrounds of Italian paintings.  But these aren't true collaborations.\nThey're more like examples of Robert Frost's\n\"good fences make good neighbors.\"  You can stick instances\nof good design together, but within each individual project,\none person has to be in control.I'm not saying that good design requires that one person think\nof everything.  There's nothing more valuable than the advice\nof someone whose judgement you trust.  But after the talking is\ndone, the decision about what to do has to rest with one person.Why is it that research can be done by collaborators and  \ndesign can't?  This is an interesting question.  I don't \nknow the answer.  Perhaps,\nif design and research converge, the best research is also\ngood design, and in fact can't be done by collaborators.\nA lot of the most famous scientists seem to have worked alone.\nBut I don't know enough to say whether there\nis a pattern here.  It could be simply that many famous scientists\nworked when collaboration was less common.Whatever the story is in the sciences, true collaboration\nseems to be vanishingly rare in the arts.  Design by committee is a\nsynonym for bad design.  Why is that so?  Is there some way to\nbeat this limitation?I'm inclined to think there isn't-- that good design requires\na dictator.  One reason is that good design has to   \nbe all of a piece.  Design is not just for humans, but\nfor individual humans.  If a design represents an idea that  \nfits in one person's head, then the idea will fit in the user's\nhead too.Related:December 2001 (rev. May 2002)\n\n(This article came about in response to some questions on\nthe LL1 mailing list.  It is now\nincorporated in Revenge of the Nerds.)When McCarthy designed Lisp in the late 1950s, it was\na radical departure from existing languages,\nthe most important of which was Fortran.Lisp embodied nine new ideas:\n1. Conditionals.  A conditional is an if-then-else\nconstruct.  We take these for granted now.  They were \ninvented\nby McCarthy in the course of developing Lisp. \n(Fortran at that time only had a conditional\ngoto, closely based on the branch instruction in the \nunderlying hardware.)  McCarthy, who was on the Algol committee, got\nconditionals into Algol, whence they spread to most other\nlanguages.2. A function type. In Lisp, functions are first class \nobjects-- they're a data type just like integers, strings,\netc, and have a literal representation, can be stored in variables,\ncan be passed as arguments, and so on.3. Recursion.  Recursion existed as a mathematical concept\nbefore Lisp of course, but Lisp was the first programming language to support\nit.  (It's arguably implicit in making functions first class\nobjects.)4. A new concept of variables.  In Lisp, all variables\nare effectively pointers. Values are what\nhave types, not variables, and assigning or binding\nvariables means copying pointers, not what they point to.5. Garbage-collection.6. Programs composed of expressions. Lisp programs are \ntrees of expressions, each of which returns a value.  \n(In some Lisps expressions\ncan return multiple values.)  This is in contrast to Fortran\nand most succeeding languages, which distinguish between\nexpressions and statements.It was natural to have this\ndistinction in Fortran because (not surprisingly in a language\nwhere the input format was punched cards) the language was\nline-oriented.  You could not nest statements.  And\nso while you needed expressions for math to work, there was\nno point in making anything else return a value, because\nthere could not be anything waiting for it.This limitation\nwent away with the arrival of block-structured languages,\nbut by then it was too late. The distinction between\nexpressions and statements was entrenched.  It spread from \nFortran into Algol and thence to both their descendants.When a language is made entirely of expressions, you can\ncompose expressions however you want.  You can say either\n(using Arc syntax)(if foo (= x 1) (= x 2))or(= x (if foo 1 2))7. A symbol type.  Symbols differ from strings in that\nyou can test equality by comparing a pointer.8. A notation for code using trees of symbols.9. The whole language always available.  \nThere is\nno real distinction between read-time, compile-time, and runtime.\nYou can compile or run code while reading, read or run code\nwhile compiling, and read or compile code at runtime.Running code at read-time lets users reprogram Lisp's syntax;\nrunning code at compile-time is the basis of macros; compiling\nat runtime is the basis of Lisp's use as an extension\nlanguage in programs like Emacs; and reading at runtime\nenables programs to communicate using s-expressions, an\nidea recently reinvented as XML.\nWhen Lisp was first invented, all these ideas were far\nremoved from ordinary programming practice, which was\ndictated largely by the hardware available in the late 1950s.Over time, the default language, embodied\nin a succession of popular languages, has\ngradually evolved toward Lisp.  1-5 are now widespread.\n6 is starting to appear in the mainstream.\nPython has a form of 7, though there doesn't seem to be\nany syntax for it.  \n8, which (with 9) is what makes Lisp macros\npossible, is so far still unique to Lisp,\nperhaps because (a) it requires those parens, or something \njust as bad, and (b) if you add that final increment of power, \nyou can no \nlonger claim to have invented a new language, but only\nto have designed a new dialect of Lisp ; -)Though useful to present-day programmers, it's\nstrange to describe Lisp in terms of its\nvariation from the random expedients other languages\nadopted.  That was not, probably, how McCarthy\nthought of it.  Lisp wasn't designed to fix the mistakes\nin Fortran; it came about more as the byproduct of an\nattempt to axiomatize computation.December 2014If the world were static, we could have monotonically increasing\nconfidence in our beliefs.  The more (and more varied) experience\na belief survived, the less likely it would be false.  Most people\nimplicitly believe something like this about their opinions.  And\nthey're justified in doing so with opinions about things that don't\nchange much, like human nature.  But you can't trust your opinions\nin the same way about things that change, which could include\npractically everything else.When experts are wrong, it's often because they're experts on an\nearlier version of the world.Is it possible to avoid that?  Can you protect yourself against\nobsolete beliefs?  To some extent, yes. I spent almost a decade\ninvesting in early stage startups, and curiously enough protecting\nyourself against obsolete beliefs is exactly what you have to do\nto succeed as a startup investor.  Most really good startup ideas\nlook like bad ideas at first, and many of those look bad specifically\nbecause some change in the world just switched them from bad to\ngood.  I spent a lot of time learning to recognize such ideas, and\nthe techniques I used may be applicable to ideas in general.The first step is to have an explicit belief in change.  People who\nfall victim to a monotonically increasing confidence in their\nopinions are implicitly concluding the world is static.  If you\nconsciously remind yourself it isn't, you start to look for change.Where should one look for it?  Beyond the moderately useful\ngeneralization that human nature doesn't change much, the unfortunate\nfact is that change is hard to predict.  This is largely a tautology\nbut worth remembering all the same: change that matters usually\ncomes from an unforeseen quarter.So I don't even try to predict it.  When I get asked in interviews\nto predict the future, I always have to struggle to come up with\nsomething plausible-sounding on the fly, like a student who hasn't\nprepared for an exam.\n[1]\nBut it's not out of laziness that I haven't\nprepared.  It seems to me that beliefs about the future are so\nrarely correct that they usually aren't worth the extra rigidity\nthey impose, and that the best strategy is simply to be aggressively\nopen-minded.  Instead of trying to point yourself in the right\ndirection, admit you have no idea what the right direction is, and\ntry instead to be super sensitive to the winds of change.It's ok to have working hypotheses, even though they may constrain\nyou a bit, because they also motivate you.  It's exciting to chase\nthings and exciting to try to guess answers.  But you have to be\ndisciplined about not letting your hypotheses harden into anything\nmore.\n[2]I believe this passive m.o. works not just for evaluating new ideas\nbut also for having them.  The way to come up with new ideas is not\nto try explicitly to, but to try to solve problems and simply not\ndiscount weird hunches you have in the process.The winds of change originate in the unconscious minds of domain\nexperts.  If you're sufficiently expert in a field, any weird idea\nor apparently irrelevant question that occurs to you is ipso facto\nworth exploring. \n[3]\n Within Y Combinator, when an idea is described\nas crazy, it's a compliment\u2014in fact, on average probably a\nhigher compliment than when an idea is described as good.Startup investors have extraordinary incentives for correcting\nobsolete beliefs.  If they can realize before other investors that\nsome apparently unpromising startup isn't, they can make a huge\namount of money.  But the incentives are more than just financial.\nInvestors' opinions are explicitly tested: startups come to them\nand they have to say yes or no, and then, fairly quickly, they learn\nwhether they guessed right.  The investors who say no to a Google\n(and there were several) will remember it for the rest of their\nlives.Anyone who must in some sense bet on ideas rather than merely\ncommenting on them has similar incentives.  Which means anyone who\nwants such incentives can have them, by turning their comments into\nbets: if you write about a topic in some fairly durable and public\nform, you'll find you worry much more about getting things right\nthan most people would in a casual conversation.\n[4]Another trick I've found to protect myself against obsolete beliefs\nis to focus initially on people rather than ideas. Though the nature\nof future discoveries is hard to predict, I've found I can predict\nquite well what sort of people will make them.  Good new ideas come\nfrom earnest, energetic, independent-minded people.Betting on people over ideas saved me countless times as an investor.\nWe thought Airbnb was a bad idea, for example. But we could tell\nthe founders were earnest, energetic, and independent-minded.\n(Indeed, almost pathologically so.)  So we suspended disbelief and\nfunded them.This too seems a technique that should be generally applicable.\nSurround yourself with the sort of people new ideas come from.  If\nyou want to notice quickly when your beliefs become obsolete, you\ncan't do better than to be friends with the people whose discoveries\nwill make them so.It's hard enough already not to become the prisoner of your own\nexpertise, but it will only get harder, because change is accelerating.\nThat's not a recent trend; change has been accelerating since the\npaleolithic era.  Ideas beget ideas.  I don't expect that to change.\nBut I could be wrong.\nNotes[1]\nMy usual trick is to talk about aspects of the present that\nmost people haven't noticed yet.[2]\nEspecially if they become well enough known that people start\nto identify them with you.  You have to be extra skeptical about\nthings you want to believe, and once a hypothesis starts to be\nidentified with you, it will almost certainly start to be in that\ncategory.[3]\nIn practice \"sufficiently expert\" doesn't require one to be\nrecognized as an expert\u2014which is a trailing indicator in any\ncase.  In many fields a year of focused work plus caring a lot would\nbe enough.[4]\nThough they are public and persist indefinitely, comments on\ne.g. forums and places like Twitter seem empirically to work like\ncasual conversation.  The threshold may be whether what you write\nhas a title.\nThanks to Sam Altman, Patrick Collison, and Robert Morris\nfor reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2010\n\n(I wrote this for Forbes, who asked me to write something\nabout the qualities we look for in founders.  In print they had to cut\nthe last item because they didn't have room.)1. DeterminationThis has turned out to be the most important quality in startup\nfounders.  We thought when we started Y Combinator that the most\nimportant quality would be intelligence.  That's the myth in the\nValley. And certainly you don't want founders to be stupid.  But\nas long as you're over a certain threshold of intelligence, what\nmatters most is determination.  You're going to hit a lot of\nobstacles.  You can't be the sort of person who gets demoralized\neasily.Bill Clerico and Rich Aberman of WePay \nare a good example.  They're\ndoing a finance startup, which means endless negotiations with big,\nbureaucratic companies.  When you're starting a startup that depends\non deals with big companies to exist, it often feels like they're\ntrying to ignore you out of existence.  But when Bill Clerico starts\ncalling you, you may as well do what he asks, because he is not\ngoing away.\n2. FlexibilityYou do not however want the sort of determination implied by phrases\nlike \"don't give up on your dreams.\"  The world of startups is so\nunpredictable that you need to be able to modify your dreams on the\nfly.  The best metaphor I've found for the combination of determination\nand flexibility you need is a running back.  \nHe's determined to get\ndownfield, but at any given moment he may need to go sideways or\neven backwards to get there.The current record holder for flexibility may be Daniel Gross of\nGreplin.  He applied to YC with \nsome bad ecommerce idea.  We told\nhim we'd fund him if he did something else.  He thought for a second,\nand said ok.  He then went through two more ideas before settling\non Greplin.  He'd only been working on it for a couple days when\nhe presented to investors at Demo Day, but he got a lot of interest.\nHe always seems to land on his feet.\n3. ImaginationIntelligence does matter a lot of course.  It seems like the type\nthat matters most is imagination.  It's not so important to be able\nto solve predefined problems quickly as to be able to come up with\nsurprising new ideas.  In the startup world, most good ideas \nseem\nbad initially.  If they were obviously good, someone would already\nbe doing them.  So you need the kind of intelligence that produces\nideas with just the right level of craziness.Airbnb is that kind of idea.  \nIn fact, when we funded Airbnb, we\nthought it was too crazy.  We couldn't believe large numbers of\npeople would want to stay in other people's places.  We funded them\nbecause we liked the founders so much.  As soon as we heard they'd\nbeen supporting themselves by selling Obama and McCain branded\nbreakfast cereal, they were in.  And it turned out the idea was on\nthe right side of crazy after all.\n4. NaughtinessThough the most successful founders are usually good people, they\ntend to have a piratical gleam in their eye.  They're not Goody\nTwo-Shoes type good.  Morally, they care about getting the big\nquestions right, but not about observing proprieties.  That's why\nI'd use the word naughty rather than evil.  They delight in \nbreaking\nrules, but not rules that matter.  This quality may be redundant\nthough; it may be implied by imagination.Sam Altman of Loopt \nis one of the most successful alumni, so we\nasked him what question we could put on the Y Combinator application\nthat would help us discover more people like him.  He said to ask\nabout a time when they'd hacked something to their advantage\u2014hacked in the sense of beating the system, not breaking into\ncomputers.  It has become one of the questions we pay most attention\nto when judging applications.\n5. FriendshipEmpirically it seems to be hard to start a startup with just \none\nfounder.  Most of the big successes have two or three.  And the\nrelationship between the founders has to be strong.  They must\ngenuinely like one another, and work well together.  Startups do\nto the relationship between the founders what a dog does to a sock:\nif it can be pulled apart, it will be.Emmett Shear and Justin Kan of Justin.tv \nare a good example of close\nfriends who work well together.  They've known each other since\nsecond grade.  They can practically read one another's minds.  I'm\nsure they argue, like all founders, but I have never once sensed\nany unresolved tension between them.Thanks to Jessica Livingston and Chris Steiner for reading drafts of this.\n\nApril 2009I usually avoid politics, but since we now seem to have an administration that's open to suggestions, I'm going to risk making one.  The single biggest thing the government could do to increase the number of startups in this country is a policy that would cost nothing: establish a new class of visa for startup founders.The biggest constraint on the number of new startups that get created in the US is not tax policy or employment law or even Sarbanes-Oxley.  It's that we won't let the people who want to start them into the country.Letting just 10,000 startup founders into the country each year could have a visible effect on the economy.  If we assume 4 people per startup, which is probably an overestimate, that's 2500 new companies.  Each year.  They wouldn't all grow as big as Google, but out of 2500 some would come close.By definition these 10,000 founders wouldn't be taking jobs from Americans: it could be part of the terms of the visa that they couldn't work for existing companies, only new ones they'd founded.  In fact they'd cause there to be \nmore jobs for Americans, because the companies they started would hire more employees as they grew.The tricky part might seem to be how one defined a startup. But that could be solved quite easily: let the market decide.  Startup investors work hard to find the best startups.  The government could not do better than to piggyback on their expertise, and use investment by recognized startup investors as the test of whether a company was a real startup.How would the government decide who's a startup investor?  The same way they decide what counts as a university for student visas. We'll establish our own accreditation procedure. We know who one another are.10,000 people is a drop in the bucket by immigration standards, but would represent a huge increase in the pool of startup founders.  I think this would have such a visible effect on the economy that it would make the legislator who introduced the bill famous.  The only way to know for sure would be to try it, and that would cost practically nothing.\nThanks to Trevor Blackwell, Paul Buchheit, Jeff Clavier, David Hornik, Jessica Livingston, Greg Mcadoo, Aydin Senkut, and Fred Wilson for reading drafts of this.Related:May 2004When people care enough about something to do it well, those who\ndo it best tend to be far better than everyone else.  There's a\nhuge gap between Leonardo and second-rate contemporaries like\nBorgognone.  You see the same gap between Raymond Chandler and the\naverage writer of detective novels.  A top-ranked professional chess\nplayer could play ten thousand games against an ordinary club player\nwithout losing once.Like chess or painting or writing novels, making money is a very\nspecialized skill.   But for some reason we treat this skill\ndifferently.  No one complains when a few people surpass all the\nrest at playing chess or writing novels, but when a few people make\nmore money than the rest, we get editorials saying this is wrong.Why?  The pattern of variation seems no different than for any other\nskill.  What causes people to react so strongly when the skill is\nmaking money?I think there are three reasons we treat making money as different:\nthe misleading model of wealth we learn as children; the disreputable\nway in which, till recently, most fortunes were accumulated; and\nthe worry that great variations in income are somehow bad for\nsociety.  As far as I can tell, the first is mistaken, the second\noutdated, and the third empirically false.  Could it be that, in a\nmodern democracy, variation in income is actually a sign of health?The Daddy Model of WealthWhen I was five I thought electricity was created by electric\nsockets.  I didn't realize there were power plants out there\ngenerating it.  Likewise, it doesn't occur to most kids that wealth\nis something that has to be generated.  It seems to be something\nthat flows from parents.Because of the circumstances in which they encounter it, children\ntend to misunderstand wealth.  They confuse it with money.  They\nthink that there is a fixed amount of it.  And they think of it as\nsomething that's distributed by authorities (and so should be\ndistributed equally), rather than something that has to be created\n(and might be created unequally).In fact, wealth is not money.  Money is just a convenient way of\ntrading one form of wealth for another.  Wealth is the underlying\nstuff\u2014the goods and services we buy.  When you travel to a\nrich or poor country, you don't have to look at people's bank\naccounts to tell which kind you're in.  You can see\nwealth\u2014in buildings and streets, in the clothes and the health\nof the people.Where does wealth come from?  People make it.  This was easier to\ngrasp when most people lived on farms, and made many of the things\nthey wanted with their own hands.  Then you could see in the house,\nthe herds, and the granary the wealth that each family created.  It\nwas obvious then too that the wealth of the world was not a fixed\nquantity that had to be shared out, like slices of a pie.  If you\nwanted more wealth, you could make it.This is just as true today, though few of us create wealth directly\nfor ourselves (except for a few vestigial domestic tasks).  Mostly\nwe create wealth for other people in exchange for money, which we\nthen trade for the forms of wealth we want. \n[1]Because kids are unable to create wealth, whatever they have has\nto be given to them.  And when wealth is something you're given,\nthen of course it seems that it should be distributed equally.\n[2]\nAs in most families it is.  The kids see to that.  \"Unfair,\" they\ncry, when one sibling gets more than another.In the real world, you can't keep living off your parents.  If you\nwant something, you either have to make it, or do something of\nequivalent value for someone else, in order to get them to give you\nenough money to buy it.  In the real world, wealth is (except for\na few specialists like thieves and speculators) something you have\nto create, not something that's distributed by Daddy.  And since\nthe ability and desire to create it vary from person to person,\nit's not made equally.You get paid by doing or making something people want, and those\nwho make more money are often simply better at doing what people\nwant.  Top actors make a lot more money than B-list actors.  The\nB-list actors might be almost as charismatic, but when people go\nto the theater and look at the list of movies playing, they want\nthat extra oomph that the big stars have.Doing what people want is not the only way to get money, of course.\nYou could also rob banks, or solicit bribes, or establish a monopoly.\nSuch tricks account for some variation in wealth, and indeed for\nsome of the biggest individual fortunes, but they are not the root\ncause of variation in income.  The root cause of variation in income,\nas Occam's Razor implies, is the same as the root cause of variation\nin every other human skill.In the United States, the CEO of a large public company makes about\n100 times as much as the average person. \n[3]\nBasketball players\nmake about 128 times as much, and baseball players 72 times as much.\nEditorials quote this kind of statistic with horror.  But I have\nno trouble imagining that one person could be 100 times as productive\nas another.  In ancient Rome the price of slaves varied by\na factor of 50 depending on their skills. \n[4]\nAnd that's without\nconsidering motivation, or the extra leverage in productivity that\nyou can get from modern technology.Editorials about athletes' or CEOs' salaries remind me of early\nChristian writers, arguing from first principles about whether the\nEarth was round, when they could just walk outside and check.\n[5]\nHow much someone's work is worth is not a policy question.  It's\nsomething the market already determines.\"Are they really worth 100 of us?\" editorialists ask.  Depends on\nwhat you mean by worth.  If you mean worth in the sense of what\npeople will pay for their skills, the answer is yes, apparently.A few CEOs' incomes reflect some kind of wrongdoing.  But are there\nnot others whose incomes really do reflect the wealth they generate?\nSteve Jobs saved a company that was in a terminal decline.  And not\nmerely in the way a turnaround specialist does, by cutting costs;\nhe had to decide what Apple's next products should be.  Few others\ncould have done it.  And regardless of the case with CEOs, it's\nhard to see how anyone could argue that the salaries of professional\nbasketball players don't reflect supply and demand.It may seem unlikely in principle that one individual could really\ngenerate so much more wealth than another.  The key to this mystery\nis to revisit that question, are they really worth 100 of us?\nWould a basketball team trade one of their players for 100\nrandom people?  What would Apple's next product look like if you\nreplaced Steve Jobs with a committee of 100 random people? \n[6]\nThese\nthings don't scale linearly.  Perhaps the CEO or the professional\nathlete has only ten times (whatever that means) the skill and\ndetermination of an ordinary person.  But it makes all the difference\nthat it's concentrated in one individual.When we say that one kind of work is overpaid and another underpaid,\nwhat are we really saying?  In a free market, prices are determined\nby what buyers want.  People like baseball more than  poetry, so\nbaseball players make more than poets.  To say that a certain kind\nof work is underpaid is thus identical with saying that people want\nthe wrong things.Well, of course people want the wrong things.  It seems odd to be\nsurprised by that.  And it seems even odder to say that it's\nunjust that certain kinds of work are underpaid. \n[7]\nThen\nyou're saying that it's unjust that people want the wrong things.\nIt's  lamentable that people prefer reality TV and corndogs to\nShakespeare and steamed vegetables, but unjust?  That seems like\nsaying that blue is heavy, or that up is circular.The appearance of the word \"unjust\" here is the unmistakable spectral\nsignature of the Daddy Model.  Why else would this idea occur in\nthis odd context?  Whereas if the speaker were still operating on\nthe Daddy Model, and saw wealth as something that flowed from a\ncommon source and had to be shared out, rather than something\ngenerated by doing what other people wanted, this is exactly what\nyou'd get on noticing that some people made much more than others.When we talk about \"unequal distribution of income,\" we should\nalso ask, where does that income come from?\n[8]\nWho made the wealth\nit represents?  Because to the extent that income varies simply\naccording to how much wealth people create, the distribution may\nbe unequal, but it's hardly unjust.Stealing ItThe second reason we tend to find great disparities of wealth\nalarming is that for most of human history the usual way to accumulate\na fortune was to steal it: in pastoral societies by cattle raiding;\nin agricultural societies by appropriating others' estates in times\nof war, and taxing them in times of peace.In conflicts, those on the winning side would receive the estates\nconfiscated from the losers.  In England in the 1060s, when William\nthe Conqueror distributed the estates of the defeated Anglo-Saxon\nnobles to his followers, the conflict was military.  By the 1530s,\nwhen Henry VIII distributed the estates of the monasteries to his\nfollowers, it was mostly political. \n[9]\nBut the principle was the\nsame.  Indeed, the same principle is at work now in Zimbabwe.In more organized societies, like China, the ruler and his officials\nused taxation instead of confiscation.  But here too we see the\nsame principle: the way to get rich was not to create wealth, but\nto serve a ruler powerful enough to appropriate it.This started to change in Europe with the rise of the middle class.\nNow we think of the middle class as people who are neither rich nor\npoor, but originally they were a distinct group.  In a feudal\nsociety, there are just two classes: a warrior aristocracy, and the\nserfs who work their estates.  The middle class were a new, third\ngroup who lived in towns and supported themselves by manufacturing\nand trade.Starting in the tenth and eleventh centuries, petty nobles and\nformer serfs banded together in towns that gradually became powerful\nenough to ignore the local feudal lords. \n[10]\nLike serfs, the middle\nclass made a living largely by creating wealth.  (In port cities\nlike Genoa and Pisa, they also engaged in piracy.) But unlike serfs\nthey had an incentive to create a lot of it.  Any wealth a serf\ncreated belonged to his master.  There was not much point in making\nmore than you could hide.  Whereas the independence of the townsmen\nallowed them to keep whatever wealth they created.Once it became possible to get rich by creating wealth, society as\na whole started to get richer very rapidly.  Nearly everything we\nhave was created by the middle class.  Indeed, the other two classes\nhave effectively disappeared in industrial societies, and their\nnames been given to either end of the middle class.  (In the original\nsense of the word, Bill Gates is middle class.)But it was not till the Industrial Revolution that wealth creation\ndefinitively replaced corruption as the best way to get rich.  In\nEngland, at least, corruption only became unfashionable (and in\nfact only started to be called \"corruption\") when there started to\nbe other, faster ways to get rich.Seventeenth-century England was much like the third world today,\nin that government office was a recognized route to wealth.  The\ngreat fortunes of that time still derived more from what we would\nnow call corruption than from commerce. \n[11]\nBy the nineteenth\ncentury that had changed.  There continued to be bribes, as there\nstill are everywhere, but politics had by then been left to men who\nwere driven more by vanity than greed.  Technology had made it\npossible to create wealth faster than you could steal it.  The\nprototypical rich man of the nineteenth century was not a courtier\nbut an industrialist.With the rise of the middle class, wealth stopped being a zero-sum\ngame.  Jobs and Wozniak didn't have to make us poor to make themselves\nrich.  Quite the opposite: they created things that made our lives\nmaterially richer.  They had to, or we wouldn't have paid for them.But since for most of the world's history the main route to wealth\nwas to steal it, we tend to be suspicious of rich people.  Idealistic\nundergraduates find their unconsciously preserved child's model of\nwealth confirmed by eminent writers of the past.  It is a case of\nthe mistaken meeting the outdated.\"Behind every great fortune, there is a crime,\" Balzac wrote.  Except\nhe didn't.  What he actually said was that a great fortune with no\napparent cause was probably due to a crime well enough executed\nthat it had been forgotten.  If we were talking about Europe in\n1000, or most of the third world today, the standard misquotation\nwould be spot on.  But Balzac lived in nineteenth-century France,\nwhere the Industrial Revolution was well advanced.  He knew you\ncould make a fortune without stealing it.  After all, he did himself,\nas a popular novelist.\n[12]Only a few countries (by no coincidence, the richest ones) have\nreached this stage.  In most, corruption still has the upper hand.\nIn most, the fastest way to get wealth is by stealing it.  And so\nwhen we see increasing differences in income in a rich country,\nthere is a tendency to worry that it's sliding back toward becoming\nanother Venezuela.  I think the opposite is happening. I think\nyou're seeing a country a full step ahead of Venezuela.The Lever of TechnologyWill technology increase the gap between rich and poor?  It will\ncertainly increase the gap between the productive and the unproductive.\nThat's the whole point of technology.   With a tractor an energetic\nfarmer could plow six times as much land in a day as he could with\na team of horses.  But only if he mastered a new kind of farming.I've seen the lever of technology grow visibly in my own time.  In\nhigh school I made money by mowing lawns and scooping ice cream at\nBaskin-Robbins.  This was the only kind of work available at the\ntime.  Now high school kids could write software or design web\nsites.  But only some of them will; the rest will still be scooping\nice cream.I remember very vividly when in 1985 improved technology made it\npossible for me to buy a computer of my own.  Within months I was\nusing it to make money as a freelance programmer.  A few years\nbefore, I couldn't have done this.  A few years before, there was\nno such thing as a freelance programmer.  But Apple created\nwealth, in the form of powerful, inexpensive computers, and programmers\nimmediately set to work using it to create more.As this example suggests, the rate at which technology increases\nour productive capacity is probably exponential, rather than linear.\nSo we should expect to see ever-increasing variation in individual\nproductivity as time goes on.   Will that increase the gap between\nrich and the poor?  Depends which gap you mean.Technology should increase the gap in income, but it seems to\ndecrease other gaps.  A hundred years ago, the rich led a different\nkind of life from ordinary people.  They lived in houses\nfull of servants, wore elaborately uncomfortable clothes, and\ntravelled about in carriages drawn by teams of horses which themselves\nrequired their own houses and servants.  Now, thanks to technology,\nthe rich live more like the average person.Cars are a good example of why.  It's possible to buy expensive,\nhandmade cars that cost hundreds of thousands of dollars.  But there\nis not much point.  Companies make more money by building a large\nnumber of ordinary cars than a small number of expensive ones.  So\na company making a mass-produced car can afford to spend a lot more\non its design.  If you buy a custom-made car, something will always\nbe breaking.  The only point of buying one now is to advertise that\nyou can.Or consider watches.  Fifty years ago, by spending a lot of money\non a watch you could get better performance.  When watches had\nmechanical movements, expensive watches kept better time.  Not any\nmore.  Since the invention of the quartz movement, an ordinary Timex\nis more accurate than a Patek Philippe costing hundreds of thousands\nof dollars.\n[13]\nIndeed, as with expensive cars, if you're determined\nto spend a lot of money on a watch, you have to put up with some\ninconvenience to do it: as well as keeping worse time, mechanical\nwatches have to be wound.The only thing technology can't cheapen is brand.  Which is precisely\nwhy we hear ever more about it.  Brand is the residue left as the\nsubstantive differences between rich and poor evaporate.  But what\nlabel you have on your stuff is a much smaller matter than having\nit versus not having it.  In 1900, if you kept a carriage, no one\nasked what year or brand it was.  If you had one, you were rich.\nAnd if you weren't rich, you took the omnibus or walked.  Now even\nthe poorest Americans drive cars, and it is only because we're so\nwell trained by advertising that we can even recognize the especially\nexpensive ones.\n[14]The same pattern has played out in industry after industry.  If\nthere is enough demand for something, technology will make it cheap\nenough to sell in large volumes, and the mass-produced versions\nwill be, if not better, at least more convenient.\n[15]\nAnd there\nis nothing the rich like more than convenience.  The rich people I\nknow drive the same cars, wear the same clothes, have the same kind\nof furniture, and eat the same foods as my other friends.  Their\nhouses are in different neighborhoods, or if in the same neighborhood\nare different sizes, but within them life is similar.  The houses\nare made using the same construction techniques and contain much\nthe same objects.  It's inconvenient to do something expensive and\ncustom.The rich spend their time more like everyone else too.  Bertie\nWooster seems long gone.  Now, most people who are rich enough not\nto work do anyway.  It's not just social pressure that makes them;\nidleness is lonely and demoralizing.Nor do we have the social distinctions there were a hundred years\nago.   The novels and etiquette manuals of that period read now\nlike descriptions of some strange tribal society.  \"With respect\nto the continuance of friendships...\" hints Mrs. Beeton's Book\nof Household Management (1880), \"it may be found necessary, in\nsome cases, for a mistress to relinquish, on assuming the responsibility\nof a household, many of those commenced in the earlier part of her\nlife.\" A woman who married a rich man was expected to drop friends\nwho didn't.  You'd seem a barbarian if you behaved that way today.\nYou'd also have a very boring life.  People still tend to segregate\nthemselves somewhat, but much more on the basis of education than\nwealth.\n[16]Materially and socially, technology seems to be decreasing the gap\nbetween the rich and the poor, not increasing it.  If Lenin walked\naround the offices of a company like Yahoo or Intel or Cisco, he'd\nthink communism had won.  Everyone would be wearing the same clothes,\nhave the same kind of office (or rather, cubicle) with the same\nfurnishings, and address one another by their first names instead\nof by honorifics.  Everything would seem exactly as he'd predicted,\nuntil he looked at their bank accounts.  Oops.Is it a problem if technology increases that gap?  It doesn't seem\nto be so far.  As it increases the gap in income, it seems to\ndecrease most other gaps.Alternative to an AxiomOne often hears a policy criticized on the grounds that it would\nincrease the income gap between rich and poor.  As if it were an\naxiom that this would be bad.  It might be true that increased\nvariation in income would be bad, but I don't see how we can say\nit's axiomatic.Indeed, it may even be false, in industrial democracies.  In a\nsociety of serfs and warlords, certainly, variation in income is a\nsign of an underlying problem.  But serfdom is not the only cause\nof variation in income.  A 747 pilot doesn't make 40 times as much\nas a checkout clerk because he is a warlord who somehow holds her\nin thrall.  His skills are simply much more valuable.I'd like to propose an alternative idea: that in a modern society,\nincreasing variation in income is a sign of health.  Technology\nseems to increase the variation in productivity at faster than\nlinear rates.  If we don't see corresponding variation in income,\nthere are three possible explanations: (a) that technical innovation\nhas stopped, (b) that the people who would create the most wealth\naren't doing it, or (c) that they aren't getting paid for it.I think we can safely say that (a) and (b) would be bad.  If you\ndisagree, try living for a year using only the resources available\nto the average Frankish nobleman in 800, and report back to us.\n(I'll be generous and not send you back to the stone age.)The only option, if you're going to have an increasingly prosperous\nsociety without increasing variation in income, seems to be (c),\nthat people will create a lot of wealth without being paid for it.\nThat Jobs and Wozniak, for example, will cheerfully work 20-hour\ndays to produce the Apple computer for a society that allows them,\nafter taxes, to keep just enough of their income to match what they\nwould have made working 9 to 5 at a big company.Will people create wealth if they can't get paid for it?  Only if\nit's fun.  People will write operating systems for free.  But they\nwon't install them, or take support calls, or train customers to\nuse them.  And at least 90% of the work that even the highest tech\ncompanies do is of this second, unedifying kind.All the unfun kinds of wealth creation slow dramatically in a society\nthat confiscates private fortunes.  We can confirm this empirically.\nSuppose you hear a strange noise that you think may be due to a\nnearby fan.  You turn the fan off, and the noise stops.  You turn\nthe fan back on, and the noise starts again.  Off, quiet.  On,\nnoise.  In the absence of other information, it would seem the noise\nis caused by the fan.At various times and places in history, whether you could accumulate\na fortune by creating wealth has been turned on and off.  Northern\nItaly in 800, off (warlords would steal it).  Northern Italy in\n1100, on.  Central France in 1100, off (still feudal).  England in\n1800, on.  England in 1974, off (98% tax on investment income).\nUnited States in 1974, on.  We've even had a twin study: West\nGermany, on;  East Germany, off.  In every case, the creation of\nwealth seems to appear and disappear like the noise of a fan as you\nswitch on and off the prospect of keeping it.There is some momentum involved.  It probably takes at least a\ngeneration to turn people into East Germans (luckily for England).\nBut if it were merely a fan we were studying, without all the extra\nbaggage that comes from the controversial topic of wealth, no one\nwould have any doubt that the fan was causing the noise.If you suppress variations in income, whether by stealing private\nfortunes, as feudal rulers used to do, or by taxing them away, as\nsome modern governments have done, the result always seems to be\nthe same.    Society as a whole ends up poorer.If I had a choice of living in a society where I was materially\nmuch better off than I am now, but was among the poorest, or in one\nwhere I was the richest, but much worse off than I am now, I'd take\nthe first option.  If I had children, it would arguably be immoral\nnot to.  It's absolute poverty you want to avoid, not relative\npoverty.  If, as the evidence so far implies, you have to have one\nor the other in your society, take relative poverty.You need rich people in your society not so much because in spending\ntheir money they create jobs, but because of what they have to do\nto get rich.  I'm not talking about the trickle-down effect\nhere.  I'm not saying that if you let Henry Ford get rich, he'll\nhire you as a waiter at his next party.  I'm saying that he'll make\nyou a tractor to replace your horse.Notes[1]\nPart of the reason this subject is so contentious is that some\nof those most vocal on the subject of wealth\u2014university\nstudents, heirs, professors, politicians, and journalists\u2014have\nthe least experience creating it.  (This phenomenon will be familiar\nto anyone who has overheard conversations about sports in a bar.)Students are mostly still on the parental dole, and have not stopped\nto think about where that money comes from.  Heirs will be on the\nparental dole for life.  Professors and politicians live within\nsocialist eddies of the economy, at one remove from the creation\nof wealth, and are paid a flat rate regardless of how hard they\nwork.  And journalists as part of their professional code segregate\nthemselves from the revenue-collecting half of the businesses they\nwork for (the ad sales department).  Many of these people never\ncome face to face with the fact that the money they receive represents\nwealth\u2014wealth that, except in the case of journalists, someone\nelse created earlier.  They live in a world in which income is\ndoled out by a central authority according to some abstract notion\nof fairness (or randomly, in the case of heirs), rather than given\nby other people in return for something they wanted, so it may seem\nto them unfair that things don't work the same in the rest of the\neconomy.(Some professors do create a great deal of wealth for\nsociety.  But the money they're paid isn't a quid pro quo.\nIt's more in the nature of an investment.)[2]\nWhen one reads about the origins of the Fabian Society, it\nsounds like something cooked up by the high-minded Edwardian\nchild-heroes of Edith Nesbit's The Wouldbegoods.[3]\nAccording to a study by the Corporate Library, the median total\ncompensation, including salary, bonus, stock grants, and the exercise\nof stock options, of S&P 500 CEOs in 2002 was $3.65 million.\nAccording to Sports Illustrated, the average NBA player's\nsalary during the 2002-03 season was $4.54 million, and the average\nmajor league baseball player's salary at the start of the 2003\nseason was $2.56 million.  According to the Bureau of Labor\nStatistics, the mean annual wage in the US in 2002 was $35,560.[4]\nIn the early empire the price of an ordinary adult slave seems\nto have been about 2,000 sestertii (e.g. Horace, Sat. ii.7.43).\nA servant girl cost 600 (Martial vi.66), while Columella (iii.3.8)\nsays that a skilled vine-dresser was worth 8,000.  A doctor, P.\nDecimus Eros Merula, paid 50,000 sestertii for his freedom (Dessau,\nInscriptiones 7812).  Seneca (Ep. xxvii.7) reports\nthat one Calvisius Sabinus paid 100,000 sestertii apiece for slaves\nlearned in the Greek classics.  Pliny (Hist. Nat. vii.39)\nsays that the highest price paid for a slave up to his time was\n700,000 sestertii, for the linguist (and presumably teacher) Daphnis,\nbut that this had since been exceeded by actors buying their own\nfreedom.Classical Athens saw a similar variation in prices.  An ordinary\nlaborer was worth about 125 to 150 drachmae.  Xenophon (Mem.\nii.5) mentions prices ranging from 50 to 6,000 drachmae (for the\nmanager of a silver mine).For more on the economics of ancient slavery see:Jones, A. H. M., \"Slavery in the Ancient World,\" Economic History\nReview, 2:9 (1956), 185-199, reprinted in Finley, M. I. (ed.),\nSlavery in Classical Antiquity, Heffer, 1964.[5]\nEratosthenes (276\u2014195 BC) used shadow lengths in different\ncities to estimate the Earth's circumference.  He was off by only\nabout 2%.[6]\nNo, and Windows, respectively.[7]\nOne of the biggest divergences between the Daddy Model and\nreality is the valuation of hard work.  In the Daddy Model, hard\nwork is in itself deserving.  In reality, wealth is measured by\nwhat one delivers, not how much effort it costs.  If I paint someone's\nhouse, the owner shouldn't pay me extra for doing it with a toothbrush.It will seem to someone still implicitly operating on the Daddy\nModel that it is unfair when someone works hard and doesn't get\npaid much.  To help clarify the matter, get rid of everyone else\nand put our worker on a desert island, hunting and gathering fruit.\nIf he's bad at it he'll work very hard and not end up with much\nfood.  Is this unfair?  Who is being unfair to him?[8]\nPart of the reason for the tenacity of the Daddy Model may be\nthe dual meaning of \"distribution.\" When economists talk about\n\"distribution of income,\" they mean statistical distribution.  But\nwhen you use the phrase frequently, you can't help associating it\nwith the other sense of the word (as in e.g. \"distribution of alms\"),\nand thereby subconsciously seeing wealth as something that flows\nfrom some central tap.  The word \"regressive\" as applied to tax\nrates has a similar effect, at least on me; how can anything\nregressive be good?[9]\n\"From the beginning of the reign Thomas Lord Roos was an assiduous\ncourtier of the young Henry VIII and was soon to reap the rewards.\nIn 1525 he was made a Knight of the Garter and given the Earldom\nof Rutland.  In the thirties his support of the breach with Rome,\nhis zeal in crushing the Pilgrimage of Grace, and his readiness to\nvote the death-penalty in the succession of spectacular treason\ntrials that punctuated Henry's erratic matrimonial progress made\nhim an obvious candidate for grants of monastic property.\"Stone, Lawrence, Family and Fortune: Studies in Aristocratic\nFinance in the Sixteenth and Seventeenth Centuries, Oxford\nUniversity Press, 1973, p. 166.[10]\nThere is archaeological evidence for large settlements earlier,\nbut it's hard to say what was happening in them.Hodges, Richard and David Whitehouse, Mohammed, Charlemagne and\nthe Origins of Europe, Cornell University Press, 1983.[11]\nWilliam Cecil and his son Robert were each in turn the most\npowerful minister of the crown, and both used their position to\namass fortunes among the largest of their times.  Robert in particular\ntook bribery to the point of treason.  \"As Secretary of State and\nthe leading advisor to King James on foreign policy, [he] was a\nspecial recipient of favour, being offered large bribes by the Dutch\nnot to make peace with Spain, and large bribes by Spain to make\npeace.\" (Stone, op. cit., p. 17.)[12]\nThough Balzac made a lot of money from writing, he was notoriously\nimprovident and was troubled by debts all his life.[13]\nA Timex will gain or lose about .5 seconds per day.  The most\naccurate mechanical watch, the Patek Philippe 10 Day Tourbillon,\nis rated at -1.5 to +2 seconds.  Its retail price is about $220,000.[14]\nIf asked to choose which was more expensive, a well-preserved\n1989 Lincoln Town Car ten-passenger limousine ($5,000) or a 2004\nMercedes S600 sedan ($122,000), the average Edwardian might well\nguess wrong.[15]\nTo\n\nRead the document and answer: What is the best thing to do in San Francisco? Here is the most relevant sentence in the context:"}]